{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f86f9b4",
   "metadata": {},
   "source": [
    "# Imports and model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e45e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from joblib import parallel_backend\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage\n",
    "\n",
    "import traceback\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f74d9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_adaboost(X_train, y_train, best_params=None, random_state=42, n_jobs=15, cv=5):\n",
    "    measurement_ada = {}\n",
    "    best_params = best_params or {}\n",
    "    \n",
    "    tree_params = {k.replace('base_', ''): v for k, v in best_params.items() \n",
    "                   if k.startswith('base_')}\n",
    "    ada_params = {k: v for k, v in best_params.items() \n",
    "                 if not k.startswith('base_')}\n",
    "    \n",
    "    # Removed n_jobs from DecisionTreeClassifier as it's not supported\n",
    "    base_estimator = DecisionTreeClassifier(random_state=random_state, **tree_params)\n",
    "    \n",
    "    # AdaBoostClassifier also doesn't support n_jobs\n",
    "    ada_model = AdaBoostClassifier(base_estimator=base_estimator,\n",
    "                                 random_state=random_state,\n",
    "                                 **ada_params)\n",
    "    \n",
    "    with parallel_backend('loky', n_jobs=n_jobs):\n",
    "        try:\n",
    "            cpu_usage = []\n",
    "            stop_flag = threading.Event()\n",
    "\n",
    "            def monitor_cpu():\n",
    "                while not stop_flag.is_set():\n",
    "                    cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "            def train_model():\n",
    "                ada_model.fit(X_train, y_train)\n",
    "\n",
    "            cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "            cpu_thread.start()\n",
    "\n",
    "            start_time = time.time()\n",
    "            train_model()\n",
    "            training_time = time.time() - start_time\n",
    "\n",
    "            stop_flag.set()\n",
    "            cpu_thread.join()\n",
    "\n",
    "            measurement_ada['Training Time (s)'] = training_time\n",
    "            measurement_ada['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "            measurement_ada['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "            f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "            \n",
    "            # Parallel processing is only available for cross-validation\n",
    "            cv_scores_ada = cross_val_score(ada_model, X_train, y_train, \n",
    "                                          cv=cv, \n",
    "                                          n_jobs=n_jobs, \n",
    "                                          scoring=f1_scorer,\n",
    "                                          verbose=1)\n",
    "\n",
    "            return cv_scores_ada, measurement_ada, ada_model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"⛔ Full error traceback:\")\n",
    "            traceback.print_exc()\n",
    "            print(f\"Error during AdaBoost training: {e}\")\n",
    "            return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28a64cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_ada(X_train, X_test, y_train, y_test, params_ada={\n",
    "    'n_estimators': 50,\n",
    "    'learning_rate': 1.0,\n",
    "    'base_max_depth': 3,\n",
    "    'base_min_samples_split': 2\n",
    "}):\n",
    "    cv_scores_ada, measurement_ada, ada_model = apply_adaboost(X_train, y_train, best_params=params_ada)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_pred_ada = ada_model.predict(X_test)\n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Predict Time (s) - \", training_time)\n",
    "    \n",
    "    cv_scores_mean_ada = np.mean(cv_scores_ada)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_ada:.4f} +/- standard deviation: {np.std(cv_scores_ada):.4f}')\n",
    "    \n",
    "    accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "    print(f'Accuracy on the test set: {accuracy_ada:.4f}')\n",
    "    \n",
    "    print(\"Resource measurements:\", measurement_ada)\n",
    "    print(classification_report(y_test, y_pred_ada, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0bfc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def show_results_ada(X_train, X_test, y_train, y_test, n_trials=100):\n",
    "    def objective(trial, X_train, y_train, cv=5):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "            'base_max_depth': trial.suggest_int('base_max_depth', 1, 50),\n",
    "            'base_min_samples_split': trial.suggest_int('base_min_samples_split', 2, 20),\n",
    "            'base_min_samples_leaf': trial.suggest_int('base_min_samples_leaf', 1, 10),\n",
    "        }\n",
    "        \n",
    "        cv_scores, _, model = apply_adaboost(X_train, y_train, best_params=params, cv=cv)\n",
    "        if cv_scores is None:\n",
    "            return 0\n",
    "        return np.mean(cv_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')    \n",
    "    with parallel_backend('loky', n_jobs=15):\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train), \n",
    "                      n_trials=n_trials,\n",
    "                      n_jobs=15)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    \n",
    "    cv_scores_ada, measurement_ada, ada_model = apply_adaboost(X_train, y_train, best_params=best_params)\n",
    "    \n",
    "    if cv_scores_ada is None:\n",
    "        print(\"Model training failed\")\n",
    "        return\n",
    "    \n",
    "    y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "    print(\"\\nUnique values in test set:\", np.unique(y_test_array))\n",
    "    print(\"Unique values in predictions:\", np.unique(y_pred_array))\n",
    "    \n",
    "    cv_scores_mean_ada = np.mean(cv_scores_ada)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test_array, y_pred_array, average='weighted')\n",
    "        accuracy = accuracy_score(y_test_array, y_pred_array)\n",
    "\n",
    "        print(\"\\nModel Evaluation Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f'Cross validation average score (F1): {cv_scores_mean_ada:.4f} +/- standard deviation: {np.std(cv_scores_ada):.4f}')\n",
    "        print(f'F1 Score on test set: {f1:.4f}')\n",
    "        print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "        print(\"\\nResource Usage:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Resource measurements:\", measurement_ada)\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(classification_report(y_test_array, y_pred_array))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during metric calculation: {str(e)}\")\n",
    "        print(\"Types in test set:\", y_test_array.dtype)\n",
    "        print(\"Types in predictions:\", y_pred_array.dtype)\n",
    "        raise\n",
    "    \n",
    "    return ada_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74035071",
   "metadata": {},
   "source": [
    "# Prep for model training cicids2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "749c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\data prep\\cicids2017_prep\\cicids2017_42feat_97percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba78db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8106bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be81fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23efdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 500000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41acd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 7500, 'Web Attacks': 7500, 'Brute Force': 7000, 'Port Scanning': 70000, 'DDoS':90000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb5513",
   "metadata": {},
   "source": [
    "# Sync classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a568ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine classes\n",
    "def combine_classes(y, class_mapping):\n",
    "    return y.map(class_mapping)\n",
    "# Define the mapping\n",
    "class_mapping = {\n",
    "    'Web Attacks': 'Other',\n",
    "    'Port Scanning': 'Other',\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'Bots': 'Bots',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'DDoS': 'DDoS',\n",
    "    'DoS': 'DoS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45b5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'DDoS', 'Port Scanning', 'Bots', 'Web Attacks',\n",
       "       'Brute Force', 'DoS'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Attack Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "604c98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all your sets\n",
    "y_train = combine_classes(y_train, class_mapping)\n",
    "y_test = combine_classes(y_test, class_mapping)\n",
    "\n",
    "y_train_scaled_rus_MMS = combine_classes(y_train_scaled_rus_MMS, class_mapping)\n",
    "y_train_resampled_scaled_MMS_SMOTE = combine_classes(y_train_resampled_scaled_MMS_SMOTE, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10794c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'DoS', 'DDoS', 'Bots', 'Other', 'Brute Force'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4d36",
   "metadata": {},
   "source": [
    "# Search best params for MMS SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbf80299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-05 22:39:14,621] A new study created in memory with name: no-name-c990a967-7e3a-4869-accf-7c4abe1be617\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 25.9min finished\n",
      "[I 2025-05-05 23:34:34,153] Trial 11 finished with value: 0.8684359691143608 and parameters: {'n_estimators': 110, 'learning_rate': 0.01358617872079761, 'base_max_depth': 3, 'base_min_samples_split': 19, 'base_min_samples_leaf': 5}. Best is trial 11 with value: 0.8684359691143608.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 59.3min finished\n",
      "[I 2025-05-06 00:32:20,398] Trial 8 finished with value: 0.9895203173361088 and parameters: {'n_estimators': 57, 'learning_rate': 0.014334809405411826, 'base_max_depth': 22, 'base_min_samples_split': 19, 'base_min_samples_leaf': 4}. Best is trial 8 with value: 0.9895203173361088.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 64.1min finished\n",
      "[I 2025-05-06 00:42:29,798] Trial 3 finished with value: 0.9897818312644258 and parameters: {'n_estimators': 63, 'learning_rate': 0.05680969283225267, 'base_max_depth': 19, 'base_min_samples_split': 4, 'base_min_samples_leaf': 9}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 64.4min finished\n",
      "[I 2025-05-06 00:43:51,770] Trial 1 finished with value: 0.9813006997312368 and parameters: {'n_estimators': 114, 'learning_rate': 0.4674630920306965, 'base_max_depth': 6, 'base_min_samples_split': 19, 'base_min_samples_leaf': 7}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 47.8min finished\n",
      "[I 2025-05-06 01:12:05,087] Trial 15 finished with value: 0.826008155860919 and parameters: {'n_estimators': 131, 'learning_rate': 0.03201856372980294, 'base_max_depth': 2, 'base_min_samples_split': 10, 'base_min_samples_leaf': 3}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 110.4min finished\n",
      "[I 2025-05-06 01:51:39,426] Trial 0 finished with value: 0.9893308935453993 and parameters: {'n_estimators': 88, 'learning_rate': 0.028109201547165234, 'base_max_depth': 34, 'base_min_samples_split': 18, 'base_min_samples_leaf': 10}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 119.0min finished\n",
      "[I 2025-05-06 02:16:22,733] Trial 4 finished with value: 0.9892367251579159 and parameters: {'n_estimators': 93, 'learning_rate': 0.1090208875835963, 'base_max_depth': 26, 'base_min_samples_split': 14, 'base_min_samples_leaf': 6}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 137.2min finished\n",
      "[I 2025-05-06 02:46:15,443] Trial 7 finished with value: 0.9894099999142464 and parameters: {'n_estimators': 103, 'learning_rate': 0.029018452899037133, 'base_max_depth': 50, 'base_min_samples_split': 13, 'base_min_samples_leaf': 6}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 79.8min finished\n",
      "[I 2025-05-06 03:04:40,929] Trial 19 finished with value: 0.9014035527373944 and parameters: {'n_estimators': 67, 'learning_rate': 0.7315461512905661, 'base_max_depth': 3, 'base_min_samples_split': 7, 'base_min_samples_leaf': 6}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 160.9min finished\n",
      "[I 2025-05-06 03:53:46,185] Trial 9 finished with value: 0.9876626055653208 and parameters: {'n_estimators': 238, 'learning_rate': 0.9156703044752289, 'base_max_depth': 6, 'base_min_samples_split': 10, 'base_min_samples_leaf': 5}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 178.1min finished\n",
      "[I 2025-05-06 04:28:15,100] Trial 2 finished with value: 0.9819764820795316 and parameters: {'n_estimators': 262, 'learning_rate': 0.02378728050955733, 'base_max_depth': 6, 'base_min_samples_split': 3, 'base_min_samples_leaf': 8}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 176.9min finished\n",
      "[I 2025-05-06 04:58:23,235] Trial 14 finished with value: 0.9894527148134742 and parameters: {'n_estimators': 180, 'learning_rate': 0.01810252710845454, 'base_max_depth': 8, 'base_min_samples_split': 16, 'base_min_samples_leaf': 10}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 176.2min finished\n",
      "[I 2025-05-06 06:01:31,913] Trial 17 finished with value: 0.9893090500541565 and parameters: {'n_estimators': 68, 'learning_rate': 0.16936112990224775, 'base_max_depth': 34, 'base_min_samples_split': 16, 'base_min_samples_leaf': 7}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 246.6min finished\n",
      "[I 2025-05-06 06:32:19,454] Trial 10 finished with value: 0.9893001148020766 and parameters: {'n_estimators': 144, 'learning_rate': 0.026909874253825693, 'base_max_depth': 28, 'base_min_samples_split': 12, 'base_min_samples_leaf': 6}. Best is trial 3 with value: 0.9897818312644258.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 263.0min finished\n",
      "[I 2025-05-06 06:34:06,067] Trial 13 finished with value: 0.9904662379122208 and parameters: {'n_estimators': 205, 'learning_rate': 0.539009025940616, 'base_max_depth': 13, 'base_min_samples_split': 7, 'base_min_samples_leaf': 6}. Best is trial 13 with value: 0.9904662379122208.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 269.2min finished\n",
      "[I 2025-05-06 07:40:24,584] Trial 16 finished with value: 0.9902224311895302 and parameters: {'n_estimators': 127, 'learning_rate': 0.25360553564228816, 'base_max_depth': 48, 'base_min_samples_split': 13, 'base_min_samples_leaf': 6}. Best is trial 13 with value: 0.9904662379122208.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 284.5min finished\n",
      "[I 2025-05-06 07:58:05,540] Trial 18 finished with value: 0.9894812726127101 and parameters: {'n_estimators': 143, 'learning_rate': 0.01682325853153426, 'base_max_depth': 12, 'base_min_samples_split': 8, 'base_min_samples_leaf': 1}. Best is trial 13 with value: 0.9904662379122208.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 187.6min finished\n",
      "[I 2025-05-06 08:32:12,085] Trial 25 finished with value: 0.9915557794990288 and parameters: {'n_estimators': 50, 'learning_rate': 0.20628268127049074, 'base_max_depth': 19, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 361.8min finished\n",
      "[I 2025-05-06 09:40:43,753] Trial 5 finished with value: 0.9913140046309863 and parameters: {'n_estimators': 262, 'learning_rate': 0.05844057288342725, 'base_max_depth': 45, 'base_min_samples_split': 15, 'base_min_samples_leaf': 10}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 292.5min finished\n",
      "[I 2025-05-06 10:37:04,978] Trial 21 finished with value: 0.9900463149614842 and parameters: {'n_estimators': 185, 'learning_rate': 0.15376226456450415, 'base_max_depth': 26, 'base_min_samples_split': 13, 'base_min_samples_leaf': 5}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 403.5min finished\n",
      "[I 2025-05-06 11:03:59,000] Trial 12 finished with value: 0.9905800847563038 and parameters: {'n_estimators': 297, 'learning_rate': 0.07961647849273866, 'base_max_depth': 37, 'base_min_samples_split': 7, 'base_min_samples_leaf': 9}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 376.1min finished\n",
      "[I 2025-05-06 12:15:59,628] Trial 20 finished with value: 0.9908226962791981 and parameters: {'n_estimators': 216, 'learning_rate': 0.2524889872265191, 'base_max_depth': 38, 'base_min_samples_split': 7, 'base_min_samples_leaf': 6}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 375.9min finished\n",
      "[I 2025-05-06 12:19:11,753] Trial 23 finished with value: 0.9893777924340783 and parameters: {'n_estimators': 172, 'learning_rate': 0.20793936106016322, 'base_max_depth': 19, 'base_min_samples_split': 3, 'base_min_samples_leaf': 4}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 374.5min finished\n",
      "[I 2025-05-06 12:35:09,824] Trial 26 finished with value: 0.9893358084613805 and parameters: {'n_estimators': 50, 'learning_rate': 0.08573365910386643, 'base_max_depth': 18, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 467.3min finished\n",
      "[I 2025-05-06 13:58:16,263] Trial 6 finished with value: 0.9901304045843192 and parameters: {'n_estimators': 274, 'learning_rate': 0.5871084569162067, 'base_max_depth': 33, 'base_min_samples_split': 5, 'base_min_samples_leaf': 5}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 420.0min finished\n",
      "[I 2025-05-06 14:31:17,041] Trial 28 finished with value: 0.99055561935683 and parameters: {'n_estimators': 50, 'learning_rate': 0.062164961676283555, 'base_max_depth': 17, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 466.9min finished\n",
      "[I 2025-05-06 14:49:20,064] Trial 24 finished with value: 0.9908556841122248 and parameters: {'n_estimators': 188, 'learning_rate': 0.1667732152916273, 'base_max_depth': 21, 'base_min_samples_split': 2, 'base_min_samples_leaf': 10}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 478.5min finished\n",
      "[I 2025-05-06 14:59:34,351] Trial 22 finished with value: 0.9894499670048085 and parameters: {'n_estimators': 239, 'learning_rate': 0.012033855365988307, 'base_max_depth': 29, 'base_min_samples_split': 7, 'base_min_samples_leaf': 5}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 415.5min finished\n",
      "[I 2025-05-06 15:53:25,598] Trial 27 finished with value: 0.9908001895795296 and parameters: {'n_estimators': 167, 'learning_rate': 0.060582964706923634, 'base_max_depth': 16, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1}. Best is trial 25 with value: 0.9915557794990288.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 414.4min finished\n",
      "[I 2025-05-06 16:02:48,654] Trial 29 finished with value: 0.9920236642223278 and parameters: {'n_estimators': 185, 'learning_rate': 0.23168053893179077, 'base_max_depth': 15, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1}. Best is trial 29 with value: 0.9920236642223278.\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model, best_params = \u001b[43mshow_results_ada\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mshow_results_ada\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n\u001b[32m     19\u001b[39m     study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, X_train, y_train), \n\u001b[32m     20\u001b[39m                   n_trials=n_trials,\n\u001b[32m     21\u001b[39m                   n_jobs=\u001b[32m15\u001b[39m)\n\u001b[32m     23\u001b[39m best_params = study.best_params\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m cv_scores_ada, measurement_ada, ada_model = \u001b[43mapply_adaboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cv_scores_ada \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel training failed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mapply_adaboost\u001b[39m\u001b[34m(X_train, y_train, best_params, random_state, n_jobs, cv)\u001b[39m\n\u001b[32m     44\u001b[39m     f1_scorer = make_scorer(f1_score, average=\u001b[33m'\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     46\u001b[39m     \u001b[38;5;66;03m# Parallel processing is only available for cross-validation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     cv_scores_ada = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mada_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf1_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cv_scores_ada, measurement_ada, ada_model\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    560\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    210\u001b[39m         skip_parameter_validation=(\n\u001b[32m    211\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    212\u001b[39m         )\n\u001b[32m    213\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    220\u001b[39m     msg = re.sub(\n\u001b[32m    221\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    224\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    308\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     60\u001b[39m config = get_config()\n\u001b[32m     61\u001b[39m iterable_with_config = (\n\u001b[32m     62\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1946\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   1947\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   1948\u001b[39m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[32m   1949\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1952\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1600\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1601\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1702\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1703\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1705\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1706\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1707\u001b[39m     time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1708\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1710\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results_ada(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "762f0bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done   5 out of   5 | elapsed: 76.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  35.96842908859253\n",
      "Cross validation average score: 0.9920 +/- standard deviation: 0.0136\n",
      "Accuracy on the test set: 0.9989\n",
      "Resource measurements: {'Training Time (s)': 3853.644735097885, 'Peak CPU Usage (%)': 86.5, 'Average CPU Usage (%)': 11.685697995120721}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.7245    0.9007    0.8031       584\n",
      "   Brute Force     0.9996    0.9989    0.9993      2745\n",
      "          DDoS     0.9998    0.9998    0.9998     38404\n",
      "           DoS     0.9979    0.9991    0.9985     58124\n",
      "Normal Traffic     0.9997    0.9990    0.9994    628518\n",
      "         Other     0.9893    0.9968    0.9931     27851\n",
      "\n",
      "      accuracy                         0.9989    756226\n",
      "     macro avg     0.9518    0.9824    0.9655    756226\n",
      "  weighted avg     0.9990    0.9989    0.9989    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_ada(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_ada={'n_estimators': 185, 'learning_rate': 0.23168053893179077, 'base_max_depth': 15, 'base_min_samples_split': 2, 'base_min_samples_leaf': 1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
