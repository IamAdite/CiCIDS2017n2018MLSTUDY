{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f86f9b4",
   "metadata": {},
   "source": [
    "# Imports and model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e45e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f74d9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rf(X_train, y_train, best_params=None, random_state=42, n_jobs=-1, cv=5): \n",
    "    measurement_rf = {}\n",
    "    best_params = best_params or {}\n",
    "\n",
    "    rf_model = RandomForestClassifier(**best_params, random_state=random_state, n_jobs=n_jobs, verbose=1)\n",
    "    \n",
    "    cpu_usage = []\n",
    "    stop_flag = threading.Event()\n",
    "\n",
    "    def monitor_cpu():\n",
    "        while not stop_flag.is_set():\n",
    "            cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "    def train_model():\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "        cpu_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_model()\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        stop_flag.set()\n",
    "        cpu_thread.join()\n",
    "\n",
    "        measurement_rf['Training Time (s)'] = training_time\n",
    "        measurement_rf['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "        measurement_rf['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "        # Modified to use F1 score\n",
    "        f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "        cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv, n_jobs=n_jobs, scoring=f1_scorer)\n",
    "\n",
    "        return cv_scores_rf, measurement_rf, rf_model\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"⛔ Full error traceback:\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"Error during Random Forest training: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "28a64cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_RF(X_train, X_test, y_train, y_test, params_rf={'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10}):\n",
    "    # Fitting the model\n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, best_params=params_rf)\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model performance\n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f'Accuracy on the test set: {accuracy_rf:.4f}')\n",
    "    \n",
    "    # Checking computational cost\n",
    "    print(\"Resource measurements:\", measurement_rf)\n",
    "    print(classification_report(y_test, y_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def show_results(X_train, X_test, y_train, y_test, n_trials=100):\n",
    "    def objective(trial, X_train, y_train, cv=5):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [None] + list(range(5, 31))),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "        }\n",
    "        \n",
    "        cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
    "        if cv_scores is None:\n",
    "            return 0\n",
    "        return np.mean(cv_scores)\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
    "        best_params = study.best_params\n",
    "    \n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, best_params=best_params)\n",
    "    \n",
    "    if cv_scores_rf is None:\n",
    "        print(\"Model training failed\")\n",
    "        return\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Convert to numpy arrays and ensure same type\n",
    "    y_test_array = np.array(y_test)\n",
    "    y_pred_array = np.array(y_pred_rf)\n",
    "    \n",
    "    # Print unique values to debug\n",
    "    print(\"\\nUnique values in test set:\", np.unique(y_test_array))\n",
    "    print(\"Unique values in predictions:\", np.unique(y_pred_array))\n",
    "    \n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test_array, y_pred_array, average='weighted')\n",
    "        accuracy = accuracy_score(y_test_array, y_pred_array)\n",
    "        \n",
    "        print(\"\\nModel Evaluation Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f'Cross validation average score (F1): {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "        print(f'F1 Score on test set: {f1:.4f}')\n",
    "        print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "        print(\"\\nResource Usage:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Resource measurements:\", measurement_rf)\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(classification_report(y_test_array, y_pred_array))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during metric calculation: {str(e)}\")\n",
    "        print(\"Types in test set:\", y_test_array.dtype)\n",
    "        print(\"Types in predictions:\", y_pred_array.dtype)\n",
    "        raise\n",
    "    \n",
    "    return rf_model, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cfc6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rf_hyperparameters(X_train, y_train, n_iter=100, cv=5, n_jobs=-1, random_state=42):\n",
    "    param_dist = {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'max_depth': [None] + list(range(5, 31)),  # Changed to direct list\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 10),\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    base_rf = RandomForestClassifier(random_state=random_state)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_rf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        verbose=2,\n",
    "        random_state=random_state,\n",
    "        n_jobs=n_jobs,\n",
    "        scoring='f1_weighted'  \n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best F1 score:\", random_search.best_score_)\n",
    "    \n",
    "    return random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74035071",
   "metadata": {},
   "source": [
    "# Prep for model training cicids2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "749c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\data prep\\cicids2017_prep\\cicids2017_42feat_97percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ba78db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8106bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be81fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23efdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 500000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41acd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 7500, 'Web Attacks': 7500, 'Brute Force': 7000, 'Port Scanning': 70000, 'DDoS':90000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb5513",
   "metadata": {},
   "source": [
    "# Sync classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a568ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine classes\n",
    "def combine_classes(y, class_mapping):\n",
    "    return y.map(class_mapping)\n",
    "# Define the mapping\n",
    "class_mapping = {\n",
    "    'Web Attacks': 'Other',\n",
    "    'Port Scanning': 'Other',\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'Bots': 'Bots',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'DDoS': 'DDoS',\n",
    "    'DoS': 'DoS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a45b5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'DDoS', 'Port Scanning', 'Bots', 'Web Attacks',\n",
       "       'Brute Force', 'DoS'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Attack Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "604c98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all your sets\n",
    "y_train = combine_classes(y_train, class_mapping)\n",
    "y_test = combine_classes(y_test, class_mapping)\n",
    "\n",
    "y_train_scaled_rus_MMS = combine_classes(y_train_scaled_rus_MMS, class_mapping)\n",
    "y_train_resampled_scaled_MMS_SMOTE = combine_classes(y_train_resampled_scaled_MMS_SMOTE, class_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4d36",
   "metadata": {},
   "source": [
    "# Search best params for MMS SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf80299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-29 17:26:27,497] A new study created in memory with name: no-name-495c7c3a-774a-4f9c-ae7c-e462d85e15b2\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.2min finished\n",
      "[I 2025-04-29 17:41:19,846] Trial 0 finished with value: 0.9892232682914923 and parameters: {'n_estimators': 80, 'max_depth': 25, 'min_samples_split': 6, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done 232 out of 232 | elapsed:  1.1min finished\n",
      "[I 2025-04-29 17:46:58,327] Trial 1 finished with value: 0.9888474475978211 and parameters: {'n_estimators': 232, 'max_depth': 29, 'min_samples_split': 14, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  99 out of  99 | elapsed:   23.9s finished\n",
      "[I 2025-04-29 17:48:59,316] Trial 2 finished with value: 0.9868622908311844 and parameters: {'n_estimators': 99, 'max_depth': 14, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 136 out of 136 | elapsed:   37.8s finished\n",
      "[I 2025-04-29 17:52:08,003] Trial 3 finished with value: 0.9872588756352354 and parameters: {'n_estimators': 136, 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   42.2s\n",
      "[Parallel(n_jobs=-1)]: Done 235 out of 235 | elapsed:   57.9s finished\n",
      "[I 2025-04-29 17:57:00,539] Trial 4 finished with value: 0.9881998404359125 and parameters: {'n_estimators': 235, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   57.9s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:  4.4min finished\n",
      "[I 2025-04-29 18:18:52,532] Trial 5 finished with value: 0.9886954490169659 and parameters: {'n_estimators': 140, 'max_depth': 14, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:   14.6s finished\n",
      "[I 2025-04-29 18:20:05,165] Trial 6 finished with value: 0.9885243388931025 and parameters: {'n_estimators': 53, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_features': 'log2'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   39.7s\n",
      "[Parallel(n_jobs=-1)]: Done 282 out of 282 | elapsed:  1.1min finished\n",
      "[I 2025-04-29 18:25:24,596] Trial 7 finished with value: 0.9829594191712647 and parameters: {'n_estimators': 282, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   53.6s\n",
      "[Parallel(n_jobs=-1)]: Done 209 out of 209 | elapsed:  1.1min finished\n",
      "[I 2025-04-29 18:30:43,331] Trial 8 finished with value: 0.9885384802349428 and parameters: {'n_estimators': 209, 'max_depth': 23, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   47.9s\n",
      "[Parallel(n_jobs=-1)]: Done 131 out of 131 | elapsed:  3.5min finished\n",
      "[I 2025-04-29 18:47:46,066] Trial 9 finished with value: 0.9832947411016434 and parameters: {'n_estimators': 131, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 0 with value: 0.9892232682914923.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:  2.0min finished\n",
      "[I 2025-04-29 18:57:07,937] Trial 10 finished with value: 0.98932617335171 and parameters: {'n_estimators': 51, 'max_depth': 25, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 10 with value: 0.98932617335171.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:  2.5min finished\n",
      "[I 2025-04-29 19:08:22,620] Trial 11 finished with value: 0.9893262247418912 and parameters: {'n_estimators': 65, 'max_depth': 25, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:  1.9min finished\n",
      "[I 2025-04-29 19:17:25,176] Trial 12 finished with value: 0.9892315742243121 and parameters: {'n_estimators': 56, 'max_depth': 25, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:  2.0min finished\n",
      "[I 2025-04-29 19:27:07,286] Trial 13 finished with value: 0.9772730664077429 and parameters: {'n_estimators': 96, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.7min finished\n",
      "[I 2025-04-29 19:34:40,043] Trial 14 finished with value: 0.9890663113556009 and parameters: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 out of 184 | elapsed:  6.0min finished\n",
      "[I 2025-04-29 20:03:42,789] Trial 15 finished with value: 0.9892427987050295 and parameters: {'n_estimators': 184, 'max_depth': 22, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  1.5min finished\n",
      "[I 2025-04-29 20:11:12,218] Trial 16 finished with value: 0.938450974702999 and parameters: {'n_estimators': 108, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 167 out of 167 | elapsed:  5.4min finished\n",
      "[I 2025-04-29 20:37:40,681] Trial 17 finished with value: 0.989296515947431 and parameters: {'n_estimators': 167, 'max_depth': 27, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done  79 out of  79 | elapsed:  2.6min finished\n",
      "[I 2025-04-29 20:50:11,336] Trial 18 finished with value: 0.9892274107639839 and parameters: {'n_estimators': 79, 'max_depth': 20, 'min_samples_split': 19, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:   19.7s finished\n",
      "[I 2025-04-29 20:51:51,323] Trial 19 finished with value: 0.9868435872953338 and parameters: {'n_estimators': 76, 'max_depth': 12, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 293 out of 293 | elapsed:  9.5min finished\n",
      "[I 2025-04-29 21:41:06,747] Trial 20 finished with value: 0.989171059005494 and parameters: {'n_estimators': 293, 'max_depth': 28, 'min_samples_split': 15, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 163 out of 163 | elapsed:  5.8min finished\n",
      "[I 2025-04-29 22:09:06,016] Trial 21 finished with value: 0.9892987953687704 and parameters: {'n_estimators': 163, 'max_depth': 27, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 167 out of 167 | elapsed:  3.4min finished\n",
      "[I 2025-04-29 22:25:51,028] Trial 22 finished with value: 0.9696833727114417 and parameters: {'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 18, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 116 out of 116 | elapsed:  4.6min finished\n",
      "[I 2025-04-29 22:47:15,475] Trial 23 finished with value: 0.9893229991480224 and parameters: {'n_estimators': 116, 'max_depth': 30, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893262247418912.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 115 out of 115 | elapsed:  4.5min finished\n",
      "[I 2025-04-29 23:08:47,802] Trial 24 finished with value: 0.9893531463439456 and parameters: {'n_estimators': 115, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 24 with value: 0.9893531463439456.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 115 out of 115 | elapsed:  4.5min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 115 out of 115 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model, best_params = \u001b[43mshow_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43moptimization_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moptuna\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mshow_results\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, optimization_type, n_trials)\u001b[39m\n\u001b[32m     30\u001b[39m y_pred_rf = rf_model.predict(X_test)\n\u001b[32m     32\u001b[39m cv_scores_mean_rf = np.mean(cv_scores_rf)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m f1 = \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mweighted\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel Evaluation Results:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    210\u001b[39m         skip_parameter_validation=(\n\u001b[32m    211\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    212\u001b[39m         )\n\u001b[32m    213\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    220\u001b[39m     msg = re.sub(\n\u001b[32m    221\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    224\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1239\u001b[39m, in \u001b[36mf1_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1070\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1071\u001b[39m     {\n\u001b[32m   1072\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1097\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1098\u001b[39m ):\n\u001b[32m   1099\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[32m   1100\u001b[39m \n\u001b[32m   1101\u001b[39m \u001b[33;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m \u001b[33;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[32m   1238\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m func_sig = signature(func)\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1413\u001b[39m, in \u001b[36mfbeta_score\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1251\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1252\u001b[39m     {\n\u001b[32m   1253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1280\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1281\u001b[39m ):\n\u001b[32m   1282\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[32m   1283\u001b[39m \n\u001b[32m   1284\u001b[39m \u001b[33;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1410\u001b[39m \u001b[33;03m    0.38...\u001b[39;00m\n\u001b[32m   1411\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1413\u001b[39m     _, _, f, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf-score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m func_sig = signature(func)\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1724\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1566\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1567\u001b[39m \n\u001b[32m   1568\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1721\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1722\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1723\u001b[39m zero_division_value = _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1724\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1727\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1501\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average != \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33maverage has to be one of \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[32m-> \u001b[39m\u001b[32m1501\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[32m   1503\u001b[39m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[32m   1504\u001b[39m present_labels = unique_labels(y_true, y_pred).tolist()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     59\u001b[39m \n\u001b[32m     60\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m check_consistent_length(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m type_true = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my_true\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m y_type = {type_true, type_pred}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:388\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[32m    387\u001b[39m first_row = y[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y.getrow(\u001b[32m0\u001b[39m).data\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.shape[\u001b[32m0\u001b[39m] > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) > \u001b[32m1\u001b[39m):\n\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m + suffix\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:262\u001b[39m, in \u001b[36m_NumPyAPIWrapper.unique_values\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<__array_function__ internals>:180\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    272\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[39m\n\u001b[32m    334\u001b[39m     aux = ar[perm]\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     ar.sort()\n\u001b[32m    337\u001b[39m     aux = ar\n\u001b[32m    338\u001b[39m mask = np.empty(aux.shape, dtype=np.bool_)\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    optimization_type='optuna',\n",
    "                                    n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee5db9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  7.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9989 +/- standard deviation: 0.0001\n",
      "Accuracy on the test set: 0.9988\n",
      "Resource measurements: {'Training Time (s)': 433.61325693130493, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 96.10674567000902}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6744    0.9401    0.7854       584\n",
      "   Brute Force     0.9946    0.9989    0.9967      2745\n",
      "          DDoS     0.9995    0.9998    0.9996     38404\n",
      "           DoS     0.9967    0.9993    0.9980     58124\n",
      "Normal Traffic     0.9999    0.9987    0.9993    628518\n",
      " Port Scanning     0.9890    0.9993    0.9941     27208\n",
      "   Web Attacks     0.9738    0.9844    0.9791       643\n",
      "\n",
      "      accuracy                         0.9988    756226\n",
      "     macro avg     0.9468    0.9887    0.9646    756226\n",
      "  weighted avg     0.9989    0.9988    0.9988    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "daf28161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 115 out of 115 | elapsed:  4.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 115 out of 115 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9988 +/- standard deviation: 0.0001\n",
      "Accuracy on the test set: 0.9988\n",
      "Resource measurements: {'Training Time (s)': 259.2027132511139, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 91.41160512434057}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6777    0.9435    0.7888       584\n",
      "   Brute Force     0.9924    0.9989    0.9956      2745\n",
      "          DDoS     0.9995    0.9998    0.9996     38404\n",
      "           DoS     0.9968    0.9993    0.9980     58124\n",
      "Normal Traffic     0.9998    0.9987    0.9993    628518\n",
      " Port Scanning     0.9890    0.9990    0.9940     27208\n",
      "   Web Attacks     0.9664    0.9844    0.9753       643\n",
      "\n",
      "      accuracy                         0.9988    756226\n",
      "     macro avg     0.9460    0.9891    0.9644    756226\n",
      "  weighted avg     0.9989    0.9988    0.9988    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 115, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
