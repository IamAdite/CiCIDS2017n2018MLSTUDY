{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f86f9b4",
   "metadata": {},
   "source": [
    "# Imports and model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e45e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74d9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rf(X_train, y_train, best_params=None, random_state=42, n_jobs=15, cv=5): \n",
    "    measurement_rf = {}\n",
    "    best_params = best_params or {}\n",
    "\n",
    "    rf_model = RandomForestClassifier(**best_params, random_state=random_state, n_jobs=n_jobs, verbose=1)\n",
    "    \n",
    "    cpu_usage = []\n",
    "    stop_flag = threading.Event()\n",
    "\n",
    "    def monitor_cpu():\n",
    "        while not stop_flag.is_set():\n",
    "            cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "    def train_model():\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "        cpu_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_model()\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        stop_flag.set()\n",
    "        cpu_thread.join()\n",
    "\n",
    "        measurement_rf['Training Time (s)'] = training_time\n",
    "        measurement_rf['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "        measurement_rf['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "        # Modified to use F1 score\n",
    "        f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "        cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv, n_jobs=n_jobs, scoring=f1_scorer)\n",
    "\n",
    "        return cv_scores_rf, measurement_rf, rf_model\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"⛔ Full error traceback:\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"Error during Random Forest training: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a64cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_RF(X_train, X_test, y_train, y_test, params_rf={'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10}):\n",
    "    # Fitting the model\n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, best_params=params_rf)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Predict Time (s) - \", training_time)\n",
    "    \n",
    "    # Evaluating the model performance\n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f'Accuracy on the test set: {accuracy_rf:.4f}')\n",
    "    \n",
    "    # Checking computational cost\n",
    "    print(\"Resource measurements:\", measurement_rf)\n",
    "    print(classification_report(y_test, y_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0bfc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def show_results(X_train, X_test, y_train, y_test, n_trials=100):\n",
    "    def objective(trial, X_train, y_train, cv=5):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [None] + list(range(5, 31))),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "        }\n",
    "        \n",
    "        cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
    "        if cv_scores is None:\n",
    "            return 0\n",
    "        return np.mean(cv_scores)\n",
    "        \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=15, best_params=best_params)\n",
    "    \n",
    "    if cv_scores_rf is None:\n",
    "        print(\"Model training failed\")\n",
    "        return\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Print unique values to debug\n",
    "    print(\"\\nUnique values in test set:\", np.unique(y_test))\n",
    "    print(\"Unique values in predictions:\", np.unique(y_pred_rf))\n",
    "    \n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "        \n",
    "        print(\"\\nModel Evaluation Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f'Cross validation average score (F1): {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "        print(f'F1 Score on test set: {f1:.4f}')\n",
    "        print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "        print(\"\\nResource Usage:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Resource measurements:\", measurement_rf)\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(classification_report(y_test, y_pred_rf))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during metric calculation: {str(e)}\")\n",
    "        print(\"Types in test set:\", y_pred_rf.dtype)\n",
    "        print(\"Types in predictions:\", y_pred_rf.dtype)\n",
    "        raise\n",
    "    \n",
    "    return rf_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74035071",
   "metadata": {},
   "source": [
    "# Prep for model training cicids2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749c9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\data prep\\cicids2017_prep\\cicids2017_42feat_97percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba78db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8106bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be81fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23efdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 500000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41acd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 7500, 'Web Attacks': 7500, 'Brute Force': 7000, 'Port Scanning': 70000, 'DDoS':90000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb5513",
   "metadata": {},
   "source": [
    "# Sync classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a568ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine classes\n",
    "def combine_classes(y, class_mapping):\n",
    "    return y.map(class_mapping)\n",
    "# Define the mapping\n",
    "class_mapping = {\n",
    "    'Web Attacks': 'Other',\n",
    "    'Port Scanning': 'Other',\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'Bots': 'Bots',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'DDoS': 'DDoS',\n",
    "    'DoS': 'DoS'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45b5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'DDoS', 'Port Scanning', 'Bots', 'Web Attacks',\n",
       "       'Brute Force', 'DoS'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Attack Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "604c98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all your sets\n",
    "y_train = combine_classes(y_train, class_mapping)\n",
    "y_test = combine_classes(y_test, class_mapping)\n",
    "\n",
    "y_train_scaled_rus_MMS = combine_classes(y_train_scaled_rus_MMS, class_mapping)\n",
    "y_train_resampled_scaled_MMS_SMOTE = combine_classes(y_train_resampled_scaled_MMS_SMOTE, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10794c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'DoS', 'DDoS', 'Bots', 'Other', 'Brute Force'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4d36",
   "metadata": {},
   "source": [
    "# Search best params for MMS SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fbf80299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-01 18:10:53,222] A new study created in memory with name: no-name-946a3546-e646-4233-8d0e-7c9c1e13d505\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 196 out of 196 | elapsed:   53.7s finished\n",
      "[I 2025-05-01 18:15:01,254] Trial 0 finished with value: 0.9880452135529687 and parameters: {'n_estimators': 196, 'max_depth': 18, 'min_samples_split': 19, 'min_samples_leaf': 9, 'max_features': 'log2'}. Best is trial 0 with value: 0.9880452135529687.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 218 out of 218 | elapsed:  7.1min finished\n",
      "[I 2025-05-01 18:50:00,689] Trial 1 finished with value: 0.9892499848987061 and parameters: {'n_estimators': 218, 'max_depth': 16, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   13.4s finished\n",
      "[I 2025-05-01 18:51:06,589] Trial 2 finished with value: 0.9873927320724161 and parameters: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 8, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   42.1s\n",
      "[Parallel(n_jobs=-1)]: Done 244 out of 244 | elapsed:   59.5s finished\n",
      "[I 2025-05-01 18:56:04,223] Trial 3 finished with value: 0.9886507176402917 and parameters: {'n_estimators': 244, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done 253 out of 253 | elapsed:   56.7s finished\n",
      "[I 2025-05-01 19:00:46,624] Trial 4 finished with value: 0.9842480031987165 and parameters: {'n_estimators': 253, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done  86 out of  86 | elapsed:   22.4s finished\n",
      "[I 2025-05-01 19:02:38,141] Trial 5 finished with value: 0.9828181360630817 and parameters: {'n_estimators': 86, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 232 out of 232 | elapsed:  1.1min finished\n",
      "[I 2025-05-01 19:08:10,991] Trial 6 finished with value: 0.9887538527198056 and parameters: {'n_estimators': 232, 'max_depth': 18, 'min_samples_split': 17, 'min_samples_leaf': 3, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 181 out of 181 | elapsed:  6.4min finished\n",
      "[I 2025-05-01 19:38:18,076] Trial 7 finished with value: 0.9892250483010375 and parameters: {'n_estimators': 181, 'max_depth': 22, 'min_samples_split': 19, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:  4.7min finished\n",
      "[I 2025-05-01 20:01:11,062] Trial 8 finished with value: 0.9891884658646533 and parameters: {'n_estimators': 140, 'max_depth': 26, 'min_samples_split': 19, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 235 out of 235 | elapsed:  1.1min finished\n",
      "[I 2025-05-01 20:06:47,364] Trial 9 finished with value: 0.9889838425843287 and parameters: {'n_estimators': 235, 'max_depth': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 296 out of 296 | elapsed:  9.4min finished\n",
      "[I 2025-05-01 20:52:14,185] Trial 10 finished with value: 0.9891054194785524 and parameters: {'n_estimators': 296, 'max_depth': 16, 'min_samples_split': 14, 'min_samples_leaf': 7, 'max_features': None}. Best is trial 1 with value: 0.9892499848987061.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 149 out of 149 | elapsed:  5.0min finished\n",
      "[I 2025-05-01 21:16:25,447] Trial 11 finished with value: 0.9893294219657305 and parameters: {'n_estimators': 149, 'max_depth': 22, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   54.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 out of 146 | elapsed:  4.3min finished\n",
      "[I 2025-05-01 21:37:24,252] Trial 12 finished with value: 0.9887203536721586 and parameters: {'n_estimators': 146, 'max_depth': 14, 'min_samples_split': 13, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:  3.5min finished\n",
      "[I 2025-05-01 21:54:31,509] Trial 13 finished with value: 0.9880622419140643 and parameters: {'n_estimators': 125, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 197 out of 197 | elapsed:  6.5min finished\n",
      "[I 2025-05-01 22:26:11,494] Trial 14 finished with value: 0.989320416418235 and parameters: {'n_estimators': 197, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  5.4min finished\n",
      "[I 2025-05-01 22:52:17,921] Trial 15 finished with value: 0.9893193665985611 and parameters: {'n_estimators': 162, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 102 out of 102 | elapsed:  1.5min finished\n",
      "[I 2025-05-01 22:59:31,079] Trial 16 finished with value: 0.938401015975721 and parameters: {'n_estimators': 102, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 198 out of 198 | elapsed:  6.5min finished\n",
      "[I 2025-05-01 23:31:20,795] Trial 17 finished with value: 0.9893029457559827 and parameters: {'n_estimators': 198, 'max_depth': 28, 'min_samples_split': 11, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.9s\n",
      "[Parallel(n_jobs=-1)]: Done 105 out of 105 | elapsed:  3.5min finished\n",
      "[I 2025-05-01 23:48:15,593] Trial 18 finished with value: 0.9892888100772449 and parameters: {'n_estimators': 105, 'max_depth': 22, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:   44.5s\n",
      "[Parallel(n_jobs=-1)]: Done 290 out of 290 | elapsed:  1.2min finished\n",
      "[I 2025-05-01 23:54:29,224] Trial 19 finished with value: 0.986778720559417 and parameters: {'n_estimators': 290, 'max_depth': 12, 'min_samples_split': 11, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.2s\n",
      "[Parallel(n_jobs=-1)]: Done 170 out of 170 | elapsed:  5.6min finished\n",
      "[I 2025-05-02 00:21:48,534] Trial 20 finished with value: 0.9892201155664739 and parameters: {'n_estimators': 170, 'max_depth': 25, 'min_samples_split': 17, 'min_samples_leaf': 4, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 161 out of 161 | elapsed:  5.4min finished\n",
      "[I 2025-05-02 00:47:46,820] Trial 21 finished with value: 0.9893204380928197 and parameters: {'n_estimators': 161, 'max_depth': 25, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 201 out of 201 | elapsed:  6.5min finished\n",
      "[I 2025-05-02 01:19:49,096] Trial 22 finished with value: 0.9893110363323349 and parameters: {'n_estimators': 201, 'max_depth': 19, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 11 with value: 0.9893294219657305.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156 out of 156 | elapsed:  5.2min finished\n",
      "[I 2025-05-02 01:44:56,723] Trial 23 finished with value: 0.989336601152106 and parameters: {'n_estimators': 156, 'max_depth': 27, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 23 with value: 0.989336601152106.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   58.8s\n",
      "[Parallel(n_jobs=-1)]: Done 149 out of 149 | elapsed:  5.0min finished\n",
      "[I 2025-05-02 02:08:58,652] Trial 24 finished with value: 0.9893284675971948 and parameters: {'n_estimators': 149, 'max_depth': 27, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 23 with value: 0.989336601152106.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.7s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  4.5min finished\n",
      "[I 2025-05-02 02:30:43,599] Trial 25 finished with value: 0.9893274396015264 and parameters: {'n_estimators': 135, 'max_depth': 27, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 23 with value: 0.989336601152106.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 113 out of 113 | elapsed:  3.8min finished\n",
      "[I 2025-05-02 02:49:03,544] Trial 26 finished with value: 0.9891838266699938 and parameters: {'n_estimators': 113, 'max_depth': 27, 'min_samples_split': 17, 'min_samples_leaf': 6, 'max_features': None}. Best is trial 23 with value: 0.989336601152106.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:  2.1min finished\n",
      "[I 2025-05-02 02:59:20,287] Trial 27 finished with value: 0.9893476111206096 and parameters: {'n_estimators': 64, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None}. Best is trial 27 with value: 0.9893476111206096.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:   17.8s finished\n",
      "[I 2025-05-02 03:00:49,438] Trial 28 finished with value: 0.9890108971537857 and parameters: {'n_estimators': 61, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 27 with value: 0.9893476111206096.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   14.0s finished\n",
      "[I 2025-05-02 03:02:01,594] Trial 29 finished with value: 0.9738348129443223 and parameters: {'n_estimators': 81, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 27 with value: 0.9893476111206096.\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=15)]: Done  64 out of  64 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=15)]: Done  64 out of  64 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in test set: ['Bots' 'Brute Force' 'DDoS' 'DoS' 'Normal Traffic' 'Other']\n",
      "Unique values in predictions: ['Bots' 'Brute Force' 'DDoS' 'DoS' 'Normal Traffic' 'Other']\n",
      "\n",
      "Model Evaluation Results:\n",
      "--------------------------------------------------\n",
      "Cross validation average score (F1): 0.9893 +/- standard deviation: 0.0191\n",
      "F1 Score on test set: 0.9988\n",
      "Accuracy on test set: 0.9988\n",
      "\n",
      "Resource Usage:\n",
      "--------------------------------------------------\n",
      "Resource measurements: {'Training Time (s)': 135.58292961120605, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 87.36620900076319}\n",
      "\n",
      "Detailed Classification Report:\n",
      "--------------------------------------------------\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots       0.66      0.96      0.78       584\n",
      "   Brute Force       0.99      1.00      1.00      2745\n",
      "          DDoS       1.00      1.00      1.00     38404\n",
      "           DoS       1.00      1.00      1.00     58124\n",
      "Normal Traffic       1.00      1.00      1.00    628518\n",
      "         Other       0.99      1.00      0.99     27851\n",
      "\n",
      "      accuracy                           1.00    756226\n",
      "     macro avg       0.94      0.99      0.96    756226\n",
      "  weighted avg       1.00      1.00      1.00    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee5db9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  6.6min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 200 out of 200 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9895 +/- standard deviation: 0.0189\n",
      "Accuracy on the test set: 0.9988\n",
      "Resource measurements: {'Training Time (s)': 393.97414994239807, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 95.66547231270364}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6753    0.9401    0.7860       584\n",
      "   Brute Force     0.9946    0.9985    0.9965      2745\n",
      "          DDoS     0.9995    0.9998    0.9996     38404\n",
      "           DoS     0.9967    0.9993    0.9980     58124\n",
      "Normal Traffic     0.9999    0.9987    0.9993    628518\n",
      "         Other     0.9886    0.9992    0.9939     27851\n",
      "\n",
      "      accuracy                         0.9988    756226\n",
      "     macro avg     0.9424    0.9893    0.9622    756226\n",
      "  weighted avg     0.9989    0.9988    0.9988    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 200, 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daf28161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 115 out of 115 | elapsed:  3.9min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 115 out of 115 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9894 +/- standard deviation: 0.0190\n",
      "Accuracy on the test set: 0.9988\n",
      "Resource measurements: {'Training Time (s)': 235.19409823417664, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 90.77283281733745}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6773    0.9452    0.7891       584\n",
      "   Brute Force     0.9935    0.9985    0.9960      2745\n",
      "          DDoS     0.9995    0.9998    0.9996     38404\n",
      "           DoS     0.9968    0.9993    0.9981     58124\n",
      "Normal Traffic     0.9998    0.9987    0.9993    628518\n",
      "         Other     0.9885    0.9988    0.9936     27851\n",
      "\n",
      "      accuracy                         0.9988    756226\n",
      "     macro avg     0.9426    0.9901    0.9626    756226\n",
      "  weighted avg     0.9989    0.9988    0.9988    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 115, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ef007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done  64 out of  64 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  0.9745879173278809\n",
      "Cross validation average score: 0.9893 +/- standard deviation: 0.0191\n",
      "Accuracy on the test set: 0.9988\n",
      "Resource measurements: {'Training Time (s)': 139.83789372444153, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 96.36789473684212}\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6608    0.9572    0.7818       584\n",
      "   Brute Force     0.9931    0.9982    0.9956      2745\n",
      "          DDoS     0.9994    0.9997    0.9996     38404\n",
      "           DoS     0.9966    0.9992    0.9979     58124\n",
      "Normal Traffic     0.9999    0.9987    0.9993    628518\n",
      "         Other     0.9886    0.9991    0.9938     27851\n",
      "\n",
      "      accuracy                         0.9988    756226\n",
      "     macro avg     0.9397    0.9920    0.9613    756226\n",
      "  weighted avg     0.9989    0.9988    0.9988    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 64, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24843eb",
   "metadata": {},
   "source": [
    "# Binary with cross-val between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02c31e",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4697dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\CrossVal between datasets\\cicids2017_training.csv\")\n",
    "\n",
    "X_train = df.drop('Attack Type', axis=1)\n",
    "y_train = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67454764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\CrossVal between datasets\\cicids2018_test_of_2017.csv\")\n",
    "\n",
    "X_test = df.drop('Attack Type', axis=1)\n",
    "y_test = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16069368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78005f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2ebd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 650000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0793514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 10000, 'Web Attacks': 10000, 'Brute Force': 10000, 'Port Scanning': 91000, 'DDoS': 130000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019fc106",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2017 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bots': 'Attack',\n",
    "    'Web Attacks': 'Attack',\n",
    "    'Port Scanning': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eac29fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2018 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bots': 'Attack',\n",
    "    'Other': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d98325cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2017)\n",
    "y_test = y_test.map(group_mapping_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf4dd0",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3594fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 15:13:50,797] A new study created in memory with name: no-name-6d5fa9a8-7198-43fa-832d-e99b85f756f1\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[W 2025-05-09 15:13:58,012] Trial 0 failed with parameters: {'n_estimators': 193, 'max_depth': 13, 'min_samples_split': 12, 'min_samples_leaf': 6, 'max_features': 'log2'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_28920\\16333617.py\", line 18, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_28920\\16333617.py\", line 12, in objective\n",
      "    cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_28920\\3657650700.py\", line 22, in apply_rf\n",
      "    train_model()\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_28920\\3657650700.py\", line 15, in train_model\n",
      "    rf_model.fit(X_train, y_train)\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1952, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1595, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1707, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-09 15:13:58,023] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model, best_params = \u001b[43mshow_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=\u001b[32m15\u001b[39m, best_params=best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results.<locals>.<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, n_trials=n_trials)\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=\u001b[32m15\u001b[39m, best_params=best_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mshow_results.<locals>.objective\u001b[39m\u001b[34m(trial, X_train, y_train, cv)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial, X_train, y_train, cv=\u001b[32m5\u001b[39m):\n\u001b[32m      4\u001b[39m     params = {\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m300\u001b[39m),\n\u001b[32m      6\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m] + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m, \u001b[32m31\u001b[39m))),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlog2\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[32m     10\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     cv_scores, _, model = \u001b[43mapply_rf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mapply_rf\u001b[39m\u001b[34m(X_train, y_train, best_params, random_state, n_jobs, cv)\u001b[39m\n\u001b[32m     19\u001b[39m cpu_thread.start()\n\u001b[32m     21\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m training_time = time.time() - start_time\n\u001b[32m     25\u001b[39m stop_flag.set()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mapply_rf.<locals>.train_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m     estimator._validate_params()\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1148\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1149\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1150\u001b[39m     )\n\u001b[32m   1151\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    445\u001b[39m trees = [\n\u001b[32m    446\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    448\u001b[39m ]\n\u001b[32m    450\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    454\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    455\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     60\u001b[39m config = get_config()\n\u001b[32m     61\u001b[39m iterable_with_config = (\n\u001b[32m     62\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1946\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   1947\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   1948\u001b[39m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[32m   1949\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1952\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1600\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1601\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1702\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1703\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1705\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1706\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1707\u001b[39m     time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1708\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1710\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46635d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  18.106565952301025\n",
      "CV F1: 0.9974 ± 0.0031\n",
      "Test Accuracy: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack     0.9908    0.3237    0.4880   2746847\n",
      "      BENIGN     0.8781    0.9994    0.9348  13390249\n",
      "\n",
      "    accuracy                         0.8844  16137096\n",
      "   macro avg     0.9345    0.6616    0.7114  16137096\n",
      "weighted avg     0.8973    0.8844    0.8588  16137096\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 7.788529872894287, 'Peak CPU (%)': 100.0, 'Avg CPU (%)': 96.71780821917808}\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_lgbm={'n_estimators': 285, 'learning_rate': 0.15274828247019778, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.6210331060028171, 'colsample_bytree': 0.9909317475119969, 'reg_alpha': 0.4761330684134722, 'reg_lambda': 1.8813380938652553})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c8e4b0",
   "metadata": {},
   "source": [
    "# Binary with cross-val on single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5752f78",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac0775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\CrossVal between datasets\\cicids2017_training.csv\")\n",
    "\n",
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5de0b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "181e63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ccb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 650000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a295def",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 10000, 'Web Attacks': 10000, 'Brute Force': 10000, 'Port Scanning': 91000, 'DDoS': 130000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80ce19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2017 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bots': 'Attack',\n",
    "    'Web Attacks': 'Attack',\n",
    "    'Port Scanning': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f188330",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2017)\n",
    "y_test = y_test.map(group_mapping_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d925213",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048410f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 20:16:29,748] A new study created in memory with name: no-name-f9cbde86-e646-4b44-8bc5-09a4ac106d60\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=15)]: Done  70 out of  70 | elapsed:   17.6s finished\n",
      "[I 2025-05-08 20:17:59,618] Trial 0 finished with value: 0.9649960036841112 and parameters: {'n_estimators': 70, 'max_depth': 6, 'min_samples_split': 17, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.9649960036841112.\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=15)]: Done 170 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=15)]: Done 277 out of 277 | elapsed:  9.5min finished\n",
      "[W 2025-05-08 20:38:18,764] Trial 1 failed with parameters: {'n_estimators': 277, 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 2, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_12872\\1676300220.py\", line 18, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_12872\\1676300220.py\", line 12, in objective\n",
      "    cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_12872\\3657650700.py\", line 34, in apply_rf\n",
      "    cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv, n_jobs=n_jobs, scoring=f1_scorer)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 562, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 214, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 309, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1952, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1595, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py\", line 1707, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-08 20:38:18,771] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rf_model, best_params = \u001b[43mshow_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=\u001b[32m15\u001b[39m, best_params=best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results.<locals>.<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, n_trials=n_trials)\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=\u001b[32m15\u001b[39m, best_params=best_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mshow_results.<locals>.objective\u001b[39m\u001b[34m(trial, X_train, y_train, cv)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial, X_train, y_train, cv=\u001b[32m5\u001b[39m):\n\u001b[32m      4\u001b[39m     params = {\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m300\u001b[39m),\n\u001b[32m      6\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m] + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m, \u001b[32m31\u001b[39m))),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlog2\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[32m     10\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     cv_scores, _, model = \u001b[43mapply_rf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mapply_rf\u001b[39m\u001b[34m(X_train, y_train, best_params, random_state, n_jobs, cv)\u001b[39m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# Modified to use F1 score\u001b[39;00m\n\u001b[32m     33\u001b[39m     f1_scorer = make_scorer(f1_score, average=\u001b[33m'\u001b[39m\u001b[33mweighted\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     cv_scores_rf = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf1_scorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cv_scores_rf, measurement_rf, rf_model\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    560\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    210\u001b[39m         skip_parameter_validation=(\n\u001b[32m    211\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    212\u001b[39m         )\n\u001b[32m    213\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    220\u001b[39m     msg = re.sub(\n\u001b[32m    221\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    223\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    224\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    308\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     60\u001b[39m config = get_config()\n\u001b[32m     61\u001b[39m iterable_with_config = (\n\u001b[32m     62\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     64\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1946\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   1947\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   1948\u001b[39m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[32m   1949\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1952\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1594\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1599\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1600\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1601\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1702\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1703\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1705\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1706\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1707\u001b[39m     time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1708\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1710\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1712\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04fd6584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=15)]: Done  64 out of  64 | elapsed:  2.9min finished\n",
      "[Parallel(n_jobs=15)]: Using backend ThreadingBackend with 15 concurrent workers.\n",
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=15)]: Done  64 out of  64 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  0.5768287181854248\n",
      "Cross validation average score: 0.9985 +/- standard deviation: 0.0006\n",
      "Accuracy on the test set: 0.9989\n",
      "Resource measurements: {'Training Time (s)': 175.13873529434204, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 85.78255122273688}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack     0.9939    0.9994    0.9967    127708\n",
      "      BENIGN     0.9999    0.9988    0.9993    628518\n",
      "\n",
      "    accuracy                         0.9989    756226\n",
      "   macro avg     0.9969    0.9991    0.9980    756226\n",
      "weighted avg     0.9989    0.9989    0.9989    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 64, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b10e810",
   "metadata": {},
   "source": [
    "# MultiClass with cross-val between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4206107",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\CrossVal between datasets\\cicids2017_training.csv\")\n",
    "\n",
    "X_train = df.drop('Attack Type', axis=1)\n",
    "y_train = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\CrossVal between datasets\\cicids2018_test_of_2017.csv\")\n",
    "\n",
    "X_test = df.drop('Attack Type', axis=1)\n",
    "y_test = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fb2a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724cdbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 650000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb64d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bots': 10000, 'Web Attacks': 10000, 'Brute Force': 10000, 'Port Scanning': 91000, 'DDoS': 130000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55932ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2017 = {\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'DoS': 'DoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'Bots': 'Bots',\n",
    "    'Web Attacks': 'Other',\n",
    "    'Port Scanning': 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7c8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7afb0e",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7fb5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 18:22:47,278] A new study created in memory with name: no-name-41646ae6-e686-4cd8-8672-c43f676f32f9\n",
      "[I 2025-05-08 18:25:19,753] Trial 0 finished with value: 0.9773941901396974 and parameters: {'n_estimators': 292, 'learning_rate': 0.009817646069583031, 'max_depth': 10, 'num_leaves': 17, 'subsample': 0.9975221533290692, 'colsample_bytree': 0.506685846212074, 'reg_alpha': 0.4110947731660012, 'reg_lambda': 0.0011018990142059504}. Best is trial 0 with value: 0.9773941901396974.\n",
      "[I 2025-05-08 18:29:46,996] Trial 1 finished with value: 0.9763116617159586 and parameters: {'n_estimators': 389, 'learning_rate': 0.005558281677372325, 'max_depth': 11, 'num_leaves': 85, 'subsample': 0.9706927476707258, 'colsample_bytree': 0.9667394297939542, 'reg_alpha': 0.05879130150671738, 'reg_lambda': 0.3880107868025716}. Best is trial 0 with value: 0.9773941901396974.\n",
      "[I 2025-05-08 18:35:03,793] Trial 2 finished with value: 0.9860617839709296 and parameters: {'n_estimators': 699, 'learning_rate': 0.0684433928303, 'max_depth': 3, 'num_leaves': 39, 'subsample': 0.5425336490895074, 'colsample_bytree': 0.8421526656319593, 'reg_alpha': 0.1164696249778467, 'reg_lambda': 0.022144548638954896}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:42:27,817] Trial 3 finished with value: 0.9757769947659151 and parameters: {'n_estimators': 704, 'learning_rate': 0.001611119830870556, 'max_depth': 14, 'num_leaves': 50, 'subsample': 0.6701290122588083, 'colsample_bytree': 0.7149828007209887, 'reg_alpha': 0.024934158450031982, 'reg_lambda': 0.003825002286116343}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:45:17,808] Trial 4 finished with value: 0.9262459782324999 and parameters: {'n_estimators': 279, 'learning_rate': 0.0012395623455427934, 'max_depth': 15, 'num_leaves': 39, 'subsample': 0.7956939331055778, 'colsample_bytree': 0.8261463810540675, 'reg_alpha': 0.027332577182604772, 'reg_lambda': 0.08473367118346115}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:45:54,783] Trial 5 finished with value: 0.9581710230354332 and parameters: {'n_estimators': 53, 'learning_rate': 0.018111441802638628, 'max_depth': 6, 'num_leaves': 88, 'subsample': 0.9695309536670853, 'colsample_bytree': 0.6765193752828512, 'reg_alpha': 0.028305604785972754, 'reg_lambda': 0.005103129438174262}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:53:22,731] Trial 6 finished with value: 0.9577450332426796 and parameters: {'n_estimators': 962, 'learning_rate': 0.001066407515358132, 'max_depth': 6, 'num_leaves': 15, 'subsample': 0.8673871041988742, 'colsample_bytree': 0.513267787037154, 'reg_alpha': 0.07728862060365572, 'reg_lambda': 0.19060467588076227}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:55:36,285] Trial 7 finished with value: 0.7708616167692827 and parameters: {'n_estimators': 269, 'learning_rate': 0.2628988302471623, 'max_depth': 15, 'num_leaves': 86, 'subsample': 0.5548417415885133, 'colsample_bytree': 0.6289470215920411, 'reg_alpha': 0.056436042694506465, 'reg_lambda': 0.056165073757315276}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 19:06:09,288] Trial 8 finished with value: 0.9858216468310761 and parameters: {'n_estimators': 982, 'learning_rate': 0.027078122031015762, 'max_depth': 10, 'num_leaves': 59, 'subsample': 0.9840519831401184, 'colsample_bytree': 0.5784119420527252, 'reg_alpha': 0.3026340927319158, 'reg_lambda': 0.36576623390728513}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 19:15:22,378] Trial 9 finished with value: 0.9865435195521494 and parameters: {'n_estimators': 782, 'learning_rate': 0.17020900593347912, 'max_depth': 9, 'num_leaves': 31, 'subsample': 0.6804410895439533, 'colsample_bytree': 0.9448604525697095, 'reg_alpha': 0.0011270587279211745, 'reg_lambda': 7.867365972878037}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:24:21,940] Trial 10 finished with value: 0.9855215771339211 and parameters: {'n_estimators': 736, 'learning_rate': 0.2915765472218258, 'max_depth': 7, 'num_leaves': 64, 'subsample': 0.6511960050774539, 'colsample_bytree': 0.9800637418578985, 'reg_alpha': 0.0014472611044288866, 'reg_lambda': 8.964024981156964}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:30:14,318] Trial 11 finished with value: 0.9860966558106672 and parameters: {'n_estimators': 731, 'learning_rate': 0.07700430739175954, 'max_depth': 4, 'num_leaves': 33, 'subsample': 0.5022090663408085, 'colsample_bytree': 0.8400971071299045, 'reg_alpha': 4.47668651721483, 'reg_lambda': 9.211542196424242}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:36:20,259] Trial 12 finished with value: 0.9841640489474228 and parameters: {'n_estimators': 837, 'learning_rate': 0.08557525688869995, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.6535301192140077, 'colsample_bytree': 0.8727019096261663, 'reg_alpha': 5.966290613905174, 'reg_lambda': 6.6461524828236715}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:43:37,676] Trial 13 finished with value: 0.9858034413238714 and parameters: {'n_estimators': 592, 'learning_rate': 0.0768596959339251, 'max_depth': 8, 'num_leaves': 31, 'subsample': 0.5218455259221572, 'colsample_bytree': 0.9083261098387785, 'reg_alpha': 0.0021290970729564247, 'reg_lambda': 1.7053953258444798}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[W 2025-05-08 19:43:53,580] Trial 14 failed with parameters: {'n_estimators': 546, 'learning_rate': 0.1351623352688896, 'max_depth': 12, 'num_leaves': 47, 'subsample': 0.7412734737535848, 'colsample_bytree': 0.7850647643174222, 'reg_alpha': 8.027291555723322, 'reg_lambda': 1.5897804036549203} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_32996\\3452006036.py\", line 17, in objective\n",
      "    cv_scores, _, model = apply_lgbm(X_train, y_train, best_params=params, cv=cv)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_32996\\839345318.py\", line 19, in apply_lgbm\n",
      "    lgbm_model.fit(X_train, y_train)\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1560, in fit\n",
      "    super().fit(\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-08 19:43:53,592] Trial 14 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lbgm_model, best_params = \u001b[43mshow_results_LGBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mshow_results_LGBM\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n",
      "\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores) \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[32m     20\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     22\u001b[39m best_params = study.best_params\n",
      "\u001b[32m     24\u001b[39m cv_scores_lgbm, measurement_lgbm, lgbm_model = apply_lgbm(X_train, y_train, best_params=best_params)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n",
      "\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n",
      "\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n",
      "\u001b[32m    385\u001b[39m \n",
      "\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n",
      "\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n",
      "\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n",
      "\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n",
      "\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n",
      "\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n",
      "\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n",
      "\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n",
      "\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n",
      "\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n",
      "\u001b[32m    247\u001b[39m ):\n",
      "\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n",
      "\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n",
      "\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n",
      "\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n",
      "\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mshow_results_LGBM.<locals>.objective\u001b[39m\u001b[34m(trial, X_train, y_train, cv)\u001b[39m\n",
      "\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial, X_train, y_train, cv=\u001b[32m5\u001b[39m):\n",
      "\u001b[32m      6\u001b[39m     params = {\n",
      "\u001b[32m      7\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1000\u001b[39m),\n",
      "\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-3\u001b[39m, \u001b[32m0.3\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m),\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-3\u001b[39m, \u001b[32m10.0\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[32m     15\u001b[39m     }\n",
      "\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     cv_scores, _, model = \u001b[43mapply_lgbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores) \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mapply_lgbm\u001b[39m\u001b[34m(X_train, y_train, best_params, n_jobs, cv)\u001b[39m\n",
      "\u001b[32m     16\u001b[39m cpu_thread.start()\n",
      "\u001b[32m     17\u001b[39m start_time = time.time()\n",
      "\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mlgbm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     21\u001b[39m training_time = time.time() - start_time\n",
      "\u001b[32m     22\u001b[39m stop_flag.set()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py:1560\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n",
      "\u001b[32m   1557\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m   1558\u001b[39m             valid_sets.append((valid_x, \u001b[38;5;28mself\u001b[39m._le.transform(valid_y)))\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1574\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n",
      "\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n",
      "\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n",
      "\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n",
      "\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n",
      "\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n",
      "\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n",
      "\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n",
      "\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n",
      "\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n",
      "\u001b[32m    311\u001b[39m     cb(\n",
      "\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n",
      "\u001b[32m    313\u001b[39m             model=booster,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n",
      "\u001b[32m    320\u001b[39m     )\n",
      "\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n",
      "\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n",
      "\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n",
      "\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m   4154\u001b[39m _safe_call(\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4159\u001b[39m )\n",
      "\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n",
      "\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f49d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  449.11964774131775\n",
      "CV F1: 0.9865 ± 0.0250\n",
      "Test Accuracy: 0.8664\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.9995    0.0269    0.0525    286191\n",
      "   Brute Force     0.9807    0.4131    0.5813    381784\n",
      "          DDoS     1.0000    0.0010    0.0019   1263933\n",
      "           DoS     0.9933    0.7062    0.8255    654300\n",
      "Normal Traffic     0.8834    0.9952    0.9360  13390249\n",
      "         Other     0.0611    0.1587    0.0883    160639\n",
      "\n",
      "      accuracy                         0.8664  16137096\n",
      "     macro avg     0.8197    0.3835    0.4142  16137096\n",
      "  weighted avg     0.8932    0.8664    0.8258  16137096\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 107.71467423439026, 'Peak CPU (%)': 100.0, 'Avg CPU (%)': 97.70577651515151}\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 64, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
