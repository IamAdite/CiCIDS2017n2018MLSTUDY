{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f86f9b4",
   "metadata": {},
   "source": [
    "# Imports and model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de316d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b59e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rf(X_train, y_train, best_params=None, random_state=42, n_jobs=-1, cv=5): \n",
    "    measurement_rf = {}\n",
    "    best_params = best_params or {}\n",
    "\n",
    "    rf_model = RandomForestClassifier(**best_params, random_state=random_state, n_jobs=n_jobs, verbose=1)\n",
    "    \n",
    "    cpu_usage = []\n",
    "    stop_flag = threading.Event()\n",
    "\n",
    "    def monitor_cpu():\n",
    "        while not stop_flag.is_set():\n",
    "            cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "    def train_model():\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "        cpu_thread.start()\n",
    "\n",
    "        start_time = time.time()\n",
    "        train_model()\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        stop_flag.set()\n",
    "        cpu_thread.join()\n",
    "\n",
    "        measurement_rf['Training Time (s)'] = training_time\n",
    "        measurement_rf['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "        measurement_rf['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "        # Modified to use F1 score\n",
    "        f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "        cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv, n_jobs=n_jobs, scoring=f1_scorer)\n",
    "\n",
    "        return cv_scores_rf, measurement_rf, rf_model\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"⛔ Full error traceback:\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"Error during Random Forest training: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57a62431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_RF(X_train, X_test, y_train, y_test, params_rf={'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10}):\n",
    "    # Fitting the model\n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, best_params=params_rf)\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(\"Predict Time (s) - \", training_time)\n",
    "    \n",
    "    # Evaluating the model performance\n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f'Accuracy on the test set: {accuracy_rf:.4f}')\n",
    "    \n",
    "    # Checking computational cost\n",
    "    print(\"Resource measurements:\", measurement_rf)\n",
    "    print(classification_report(y_test, y_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db845f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def show_results(X_train, X_test, y_train, y_test, n_trials=100):\n",
    "    def objective(trial, X_train, y_train, cv=5):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [None] + list(range(5, 31))),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "        }\n",
    "        \n",
    "        cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
    "        if cv_scores is None:\n",
    "            return 0\n",
    "        return np.mean(cv_scores)\n",
    "        \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    \n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=15, best_params=best_params)\n",
    "    \n",
    "    if cv_scores_rf is None:\n",
    "        print(\"Model training failed\")\n",
    "        return\n",
    "    \n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Print unique values to debug\n",
    "    print(\"\\nUnique values in test set:\", np.unique(y_test))\n",
    "    print(\"Unique values in predictions:\", np.unique(y_pred_rf))\n",
    "    \n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "        \n",
    "        print(\"\\nModel Evaluation Results:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(f'Cross validation average score (F1): {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "        print(f'F1 Score on test set: {f1:.4f}')\n",
    "        print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "        print(\"\\nResource Usage:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Resource measurements:\", measurement_rf)\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(classification_report(y_test, y_pred_rf))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during metric calculation: {str(e)}\")\n",
    "        print(\"Types in test set:\", y_pred_rf.dtype)\n",
    "        print(\"Types in predictions:\", y_pred_rf.dtype)\n",
    "        raise\n",
    "    \n",
    "    return rf_model, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74035071",
   "metadata": {},
   "source": [
    "# Prep for model training cicids2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "749c9cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\790043214.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df = pd.read_csv(\"..\\cicids2018_training.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2018_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ba78db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8106bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be81fde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "23efdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41acd109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb5513",
   "metadata": {},
   "source": [
    "# Sync classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d5aa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to combine classes\n",
    "def combine_classes(y, class_mapping):\n",
    "    return y.map(class_mapping)\n",
    "# Define the mapping\n",
    "group_mapping_2018 = {\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'DoS': 'DoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'Bot': 'Bots',\n",
    "    'Infilteration': 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a45b5052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'Bot', 'DoS', 'Brute Force', 'DDoS',\n",
       "       'Infilteration'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Attack Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "604c98fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all your sets\n",
    "y_train = combine_classes(y_train, group_mapping_2018)\n",
    "y_test = combine_classes(y_test, group_mapping_2018)\n",
    "\n",
    "y_train_scaled_rus_MMS = combine_classes(y_train_scaled_rus_MMS, group_mapping_2018)\n",
    "y_train_resampled_scaled_MMS_SMOTE = combine_classes(y_train_resampled_scaled_MMS_SMOTE, group_mapping_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d4d36",
   "metadata": {},
   "source": [
    "# Search best params for MMS SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf80299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-09 15:13:57,465] A new study created in memory with name: no-name-0296d409-34ac-4373-96f2-bfeb5ee6d161\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.6min\n",
      "[W 2025-05-09 15:15:45,762] Trial 0 failed with parameters: {'n_estimators': 122, 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': None} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ML\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2710070721.py\", line 18, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=n_trials)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2710070721.py\", line 12, in objective\n",
      "    cv_scores, _, model = apply_rf(X_train, y_train, best_params=params, cv=cv)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2897538565.py\", line 22, in apply_rf\n",
      "    train_model()\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2897538565.py\", line 15, in train_model\n",
      "    rf_model.fit(X_train, y_train)\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 487, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\joblib\\parallel.py\", line 2007, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\joblib\\parallel.py\", line 1650, in _get_outputs\n",
      "    yield from self._retrieve()\n",
      "  File \"c:\\ML\\Lib\\site-packages\\joblib\\parallel.py\", line 1762, in _retrieve\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-09 15:15:45,945] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lbgm_model, best_params = \u001b[43mshow_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=-\u001b[32m1\u001b[39m, best_params=best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mshow_results.<locals>.<lambda>\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores)\n\u001b[32m     17\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m study.optimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m, n_trials=n_trials)\n\u001b[32m     19\u001b[39m best_params = study.best_params\n\u001b[32m     21\u001b[39m cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, n_jobs=-\u001b[32m1\u001b[39m, best_params=best_params)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mshow_results.<locals>.objective\u001b[39m\u001b[34m(trial, X_train, y_train, cv)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial, X_train, y_train, cv=\u001b[32m5\u001b[39m):\n\u001b[32m      4\u001b[39m     params = {\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m300\u001b[39m),\n\u001b[32m      6\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m, [\u001b[38;5;28;01mNone\u001b[39;00m] + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m, \u001b[32m31\u001b[39m))),\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_categorical(\u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m, [\u001b[33m'\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlog2\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[32m     10\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     cv_scores, _, model = \u001b[43mapply_rf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     14\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mapply_rf\u001b[39m\u001b[34m(X_train, y_train, best_params, random_state, n_jobs, cv)\u001b[39m\n\u001b[32m     19\u001b[39m cpu_thread.start()\n\u001b[32m     21\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m training_time = time.time() - start_time\n\u001b[32m     25\u001b[39m stop_flag.set()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mapply_rf.<locals>.train_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ML\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5db9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  9.027400255203247\n",
      "CV F1: 0.9939 ± 0.0106\n",
      "Test Accuracy: 0.9990\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.6898    0.9521    0.8000       584\n",
      "   Brute Force     0.9993    0.9989    0.9991      2745\n",
      "          DDoS     0.9998    0.9998    0.9998     38404\n",
      "           DoS     0.9977    0.9998    0.9987     58124\n",
      "Normal Traffic     0.9999    0.9989    0.9994    628518\n",
      "         Other     0.9889    0.9994    0.9941     27851\n",
      "\n",
      "      accuracy                         0.9990    756226\n",
      "     macro avg     0.9459    0.9915    0.9652    756226\n",
      "  weighted avg     0.9991    0.9990    0.9990    756226\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 38.28263568878174, 'Peak CPU (%)': 99.1, 'Avg CPU (%)': 74.17698412698412}\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_lgbm={'n_estimators': 228, 'learning_rate': 0.07241523535942174, 'max_depth': 14, 'num_leaves': 79, 'subsample': 0.5650088660864082, 'colsample_bytree': 0.8850730957587873, 'reg_alpha': 0.31650105405212536, 'reg_lambda': 3.8724602641849213})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3dbf20",
   "metadata": {},
   "source": [
    "# Binary with cross-val between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88538f2",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2018_training.csv\")\n",
    "\n",
    "X_train = df.drop('Attack Type', axis=1)\n",
    "y_train = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792edeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2017_test_of_2018.csv\")\n",
    "\n",
    "X_test = df.drop('Attack Type', axis=1)\n",
    "y_test = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcdfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab517b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a862a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2017 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bots': 'Attack',\n",
    "    'Other': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2018 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bot': 'Attack',\n",
    "    'Infilteration': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4dd762",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2017)\n",
    "y_test = y_test.map(group_mapping_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47460a04",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f9b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 15:52:45,745] A new study created in memory with name: no-name-f6c15b4c-ba73-4338-94d7-8d68efd3f5c4\n",
      "[I 2025-05-08 15:53:20,941] Trial 0 finished with value: 0.9463691980440976 and parameters: {'n_estimators': 236, 'learning_rate': 0.0031743583016229497, 'max_depth': 5, 'num_leaves': 10, 'subsample': 0.6599208139910135, 'colsample_bytree': 0.9866917940844662, 'reg_alpha': 0.008200707779018225, 'reg_lambda': 3.924635944296941}. Best is trial 0 with value: 0.9463691980440976.\n",
      "[I 2025-05-08 15:54:15,987] Trial 1 finished with value: 0.9947781486089827 and parameters: {'n_estimators': 251, 'learning_rate': 0.05653593901676786, 'max_depth': 7, 'num_leaves': 61, 'subsample': 0.8930974500057347, 'colsample_bytree': 0.9318301386899517, 'reg_alpha': 0.0018429557707955522, 'reg_lambda': 0.13314839100032558}. Best is trial 1 with value: 0.9947781486089827.\n",
      "[I 2025-05-08 15:56:22,370] Trial 2 finished with value: 0.9962936879063552 and parameters: {'n_estimators': 717, 'learning_rate': 0.047746697771896454, 'max_depth': 13, 'num_leaves': 54, 'subsample': 0.6133549776994832, 'colsample_bytree': 0.5886028048835438, 'reg_alpha': 0.009846584850170986, 'reg_lambda': 1.114705915295651}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 15:56:40,788] Trial 3 finished with value: 0.9877770272450593 and parameters: {'n_estimators': 59, 'learning_rate': 0.07645496986790909, 'max_depth': 13, 'num_leaves': 88, 'subsample': 0.5316040185526674, 'colsample_bytree': 0.7945324395996913, 'reg_alpha': 2.1365208994206975, 'reg_lambda': 0.01788585718852827}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 15:57:56,853] Trial 4 finished with value: 0.9806611579227988 and parameters: {'n_estimators': 629, 'learning_rate': 0.009655263658268317, 'max_depth': 6, 'num_leaves': 19, 'subsample': 0.6866800726846809, 'colsample_bytree': 0.8240633524933605, 'reg_alpha': 4.242021665629893, 'reg_lambda': 0.0011923460407637985}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 15:58:25,673] Trial 5 finished with value: 0.9819730333026635 and parameters: {'n_estimators': 333, 'learning_rate': 0.06037511107257368, 'max_depth': 3, 'num_leaves': 58, 'subsample': 0.5446988308478431, 'colsample_bytree': 0.649220300354001, 'reg_alpha': 0.001893998276459852, 'reg_lambda': 2.2672125061413873}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:00:33,414] Trial 6 finished with value: 0.9865845547413743 and parameters: {'n_estimators': 968, 'learning_rate': 0.006289159894946653, 'max_depth': 13, 'num_leaves': 25, 'subsample': 0.925520456866081, 'colsample_bytree': 0.5604258791211477, 'reg_alpha': 0.005260676476460552, 'reg_lambda': 0.14335689005712562}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:01:45,679] Trial 7 finished with value: 0.9049366485069557 and parameters: {'n_estimators': 872, 'learning_rate': 0.003963863981294717, 'max_depth': 3, 'num_leaves': 57, 'subsample': 0.8062537010561852, 'colsample_bytree': 0.7536581630011489, 'reg_alpha': 1.501768055455917, 'reg_lambda': 0.02565797222539746}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:03:24,565] Trial 8 finished with value: 0.9855868035283466 and parameters: {'n_estimators': 685, 'learning_rate': 0.007897893016514425, 'max_depth': 12, 'num_leaves': 68, 'subsample': 0.6284474662591033, 'colsample_bytree': 0.6202657115381032, 'reg_alpha': 0.09810146431632431, 'reg_lambda': 0.9499832685986584}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:04:58,407] Trial 9 finished with value: 0.9766172004181465 and parameters: {'n_estimators': 760, 'learning_rate': 0.16725881543184973, 'max_depth': 15, 'num_leaves': 28, 'subsample': 0.5309719813709346, 'colsample_bytree': 0.5111579668173878, 'reg_alpha': 0.15863989311062182, 'reg_lambda': 0.0018498896448140485}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:06:05,637] Trial 10 finished with value: 0.9061372355050631 and parameters: {'n_estimators': 457, 'learning_rate': 0.0010249851472627705, 'max_depth': 10, 'num_leaves': 38, 'subsample': 0.7660640364120377, 'colsample_bytree': 0.6646764853334597, 'reg_alpha': 0.03853004574604535, 'reg_lambda': 0.7226782852571213}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:07:14,480] Trial 11 finished with value: 0.9958194632538959 and parameters: {'n_estimators': 507, 'learning_rate': 0.03680266593527361, 'max_depth': 8, 'num_leaves': 78, 'subsample': 0.8996138281740725, 'colsample_bytree': 0.9326067328155958, 'reg_alpha': 0.0011029605159085813, 'reg_lambda': 0.21633774719000998}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:08:52,205] Trial 12 finished with value: 0.9943200840627794 and parameters: {'n_estimators': 548, 'learning_rate': 0.02711162114588064, 'max_depth': 9, 'num_leaves': 83, 'subsample': 0.9695300317914942, 'colsample_bytree': 0.8914978891140815, 'reg_alpha': 0.015035067464229774, 'reg_lambda': 8.5196070766723}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:10:08,658] Trial 13 finished with value: 0.9961430430008594 and parameters: {'n_estimators': 459, 'learning_rate': 0.2162013700640636, 'max_depth': 9, 'num_leaves': 100, 'subsample': 0.841736179972089, 'colsample_bytree': 0.6929934862437619, 'reg_alpha': 0.0011607336237256464, 'reg_lambda': 0.3714656662871559}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:12:05,903] Trial 14 finished with value: 0.995814593553467 and parameters: {'n_estimators': 806, 'learning_rate': 0.2800002188269327, 'max_depth': 11, 'num_leaves': 100, 'subsample': 0.8232159235341305, 'colsample_bytree': 0.6983785819965894, 'reg_alpha': 0.02097518599577214, 'reg_lambda': 0.5214342356433539}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:12:58,218] Trial 15 finished with value: 0.9949281681313732 and parameters: {'n_estimators': 361, 'learning_rate': 0.13686698476913112, 'max_depth': 15, 'num_leaves': 46, 'subsample': 0.726677208184323, 'colsample_bytree': 0.582602964730557, 'reg_alpha': 0.00460918203518879, 'reg_lambda': 0.03006897511547077}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:14:26,648] Trial 16 finished with value: 0.993748163409259 and parameters: {'n_estimators': 619, 'learning_rate': 0.018106503004056147, 'max_depth': 10, 'num_leaves': 44, 'subsample': 0.6002571542886607, 'colsample_bytree': 0.7157789903459484, 'reg_alpha': 0.4533423648841086, 'reg_lambda': 1.8808088451789091}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:16:29,336] Trial 17 finished with value: 0.9946340243674842 and parameters: {'n_estimators': 969, 'learning_rate': 0.148503888075922, 'max_depth': 8, 'num_leaves': 73, 'subsample': 0.8391306838880145, 'colsample_bytree': 0.5083016639789392, 'reg_alpha': 0.0036137318128490266, 'reg_lambda': 0.29351043127180604}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:17:44,302] Trial 18 finished with value: 0.9958040227248268 and parameters: {'n_estimators': 450, 'learning_rate': 0.0920689640272419, 'max_depth': 13, 'num_leaves': 100, 'subsample': 0.744926605785305, 'colsample_bytree': 0.5805842456974566, 'reg_alpha': 0.060677923933464786, 'reg_lambda': 0.04380974262113292}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:19:08,809] Trial 19 finished with value: 0.8627389377012985 and parameters: {'n_estimators': 743, 'learning_rate': 0.27350139157085906, 'max_depth': 11, 'num_leaves': 89, 'subsample': 0.5991338270151398, 'colsample_bytree': 0.7568874955941332, 'reg_alpha': 0.013275037327178, 'reg_lambda': 0.007468456776108062}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:19:22,912] Trial 20 finished with value: 0.960037767075762 and parameters: {'n_estimators': 83, 'learning_rate': 0.034673083117604954, 'max_depth': 5, 'num_leaves': 47, 'subsample': 0.6955382157955572, 'colsample_bytree': 0.6380395998816546, 'reg_alpha': 0.3711350154638153, 'reg_lambda': 7.912309377470381}. Best is trial 2 with value: 0.9962936879063552.\n",
      "[I 2025-05-08 16:20:44,101] Trial 21 finished with value: 0.9963901081081195 and parameters: {'n_estimators': 540, 'learning_rate': 0.0412291844697367, 'max_depth': 8, 'num_leaves': 80, 'subsample': 0.8801436785798233, 'colsample_bytree': 0.8295024039044725, 'reg_alpha': 0.001247313703956749, 'reg_lambda': 0.2804975824595617}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:22:12,671] Trial 22 finished with value: 0.9941434698633815 and parameters: {'n_estimators': 575, 'learning_rate': 0.018879177837675867, 'max_depth': 9, 'num_leaves': 67, 'subsample': 0.8615608527138604, 'colsample_bytree': 0.8261036199951639, 'reg_alpha': 0.0011387133345446398, 'reg_lambda': 0.07311759735299318}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:23:01,756] Trial 23 finished with value: 0.9960396033194101 and parameters: {'n_estimators': 381, 'learning_rate': 0.04558319959377538, 'max_depth': 7, 'num_leaves': 94, 'subsample': 0.7849422274877426, 'colsample_bytree': 0.6996286354797678, 'reg_alpha': 0.002837957909445292, 'reg_lambda': 0.41625692109185347}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:24:54,862] Trial 24 finished with value: 0.9961770686106519 and parameters: {'n_estimators': 652, 'learning_rate': 0.09574584216328985, 'max_depth': 10, 'num_leaves': 79, 'subsample': 0.978800575155678, 'colsample_bytree': 0.8477386848890096, 'reg_alpha': 0.0010138672102991094, 'reg_lambda': 1.0310273218054447}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:26:42,432] Trial 25 finished with value: 0.9958253247032373 and parameters: {'n_estimators': 648, 'learning_rate': 0.0952150816157797, 'max_depth': 14, 'num_leaves': 77, 'subsample': 0.9890406629425498, 'colsample_bytree': 0.8431950155704411, 'reg_alpha': 0.008450242946691234, 'reg_lambda': 1.4739359420483271}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:28:51,321] Trial 26 finished with value: 0.9941434053233987 and parameters: {'n_estimators': 876, 'learning_rate': 0.024563134595749065, 'max_depth': 11, 'num_leaves': 68, 'subsample': 0.9557391534400248, 'colsample_bytree': 0.8740815990792854, 'reg_alpha': 0.033631701180419964, 'reg_lambda': 1.121652058740264}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:30:38,638] Trial 27 finished with value: 0.9944959187083207 and parameters: {'n_estimators': 696, 'learning_rate': 0.106101563340673, 'max_depth': 12, 'num_leaves': 52, 'subsample': 0.9321117503334593, 'colsample_bytree': 0.7868841885739486, 'reg_alpha': 0.0023621577997522607, 'reg_lambda': 3.069728728642099}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:32:38,099] Trial 28 finished with value: 0.9938770055554332 and parameters: {'n_estimators': 805, 'learning_rate': 0.012068516961966444, 'max_depth': 10, 'num_leaves': 64, 'subsample': 0.8794064108400984, 'colsample_bytree': 0.9104678618617283, 'reg_alpha': 0.006499866987224273, 'reg_lambda': 0.06683545055222401}. Best is trial 21 with value: 0.9963901081081195.\n",
      "[I 2025-05-08 16:33:55,786] Trial 29 finished with value: 0.9968405670785969 and parameters: {'n_estimators': 579, 'learning_rate': 0.04830183624874727, 'max_depth': 7, 'num_leaves': 75, 'subsample': 0.9862775637951985, 'colsample_bytree': 0.8630727733597596, 'reg_alpha': 0.010540632869788014, 'reg_lambda': 4.649150640158859}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:35:01,873] Trial 30 finished with value: 0.9790192394666452 and parameters: {'n_estimators': 567, 'learning_rate': 0.012709668755970604, 'max_depth': 5, 'num_leaves': 37, 'subsample': 0.9271984837971866, 'colsample_bytree': 0.9868121096121282, 'reg_alpha': 0.010187860151518164, 'reg_lambda': 4.170280284841252}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:36:48,591] Trial 31 finished with value: 0.9957769553236988 and parameters: {'n_estimators': 710, 'learning_rate': 0.05557539753640221, 'max_depth': 7, 'num_leaves': 82, 'subsample': 0.9995351768735483, 'colsample_bytree': 0.85748221406455, 'reg_alpha': 0.003428308990112722, 'reg_lambda': 4.0341485395784416}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:38:01,818] Trial 32 finished with value: 0.9966285906813326 and parameters: {'n_estimators': 602, 'learning_rate': 0.06917654288805901, 'max_depth': 6, 'num_leaves': 73, 'subsample': 0.9623493997820359, 'colsample_bytree': 0.9455806708695783, 'reg_alpha': 0.024782742264764714, 'reg_lambda': 0.6849178447577864}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:39:08,688] Trial 33 finished with value: 0.9962111317803707 and parameters: {'n_estimators': 526, 'learning_rate': 0.06457062682430974, 'max_depth': 6, 'num_leaves': 87, 'subsample': 0.9467950865124682, 'colsample_bytree': 0.9568890428417451, 'reg_alpha': 0.02190129968419494, 'reg_lambda': 0.20477746853721837}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:40:28,230] Trial 34 finished with value: 0.9965140424756541 and parameters: {'n_estimators': 594, 'learning_rate': 0.03906601154965324, 'max_depth': 6, 'num_leaves': 75, 'subsample': 0.9105786286988868, 'colsample_bytree': 0.9411567326100128, 'reg_alpha': 0.060096114083054826, 'reg_lambda': 0.6421381705824475}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:41:04,557] Trial 35 finished with value: 0.9863527498001584 and parameters: {'n_estimators': 298, 'learning_rate': 0.030745144543485946, 'max_depth': 6, 'num_leaves': 72, 'subsample': 0.9075601829197586, 'colsample_bytree': 0.9645339744621263, 'reg_alpha': 0.12184339697642282, 'reg_lambda': 0.6217004228737886}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:42:09,682] Trial 36 finished with value: 0.9885044668453606 and parameters: {'n_estimators': 606, 'learning_rate': 0.04348799077973518, 'max_depth': 4, 'num_leaves': 72, 'subsample': 0.8750172823228156, 'colsample_bytree': 0.9192965048871953, 'reg_alpha': 0.06636313998625508, 'reg_lambda': 0.12914601847264134}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:42:40,792] Trial 37 finished with value: 0.9839736567996831 and parameters: {'n_estimators': 173, 'learning_rate': 0.01911907314890996, 'max_depth': 8, 'num_leaves': 63, 'subsample': 0.9070751144710125, 'colsample_bytree': 0.9522232726576957, 'reg_alpha': 0.3057330172356683, 'reg_lambda': 2.6981345992148538}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:43:34,892] Trial 38 finished with value: 0.9964234173848819 and parameters: {'n_estimators': 461, 'learning_rate': 0.07058804671198698, 'max_depth': 6, 'num_leaves': 93, 'subsample': 0.951055404120889, 'colsample_bytree': 0.795746913937698, 'reg_alpha': 0.034366095321979616, 'reg_lambda': 4.790088829826755}. Best is trial 29 with value: 0.9968405670785969.\n",
      "[I 2025-05-08 16:44:17,859] Trial 39 finished with value: 0.9968795765148493 and parameters: {'n_estimators': 403, 'learning_rate': 0.12429233548545239, 'max_depth': 4, 'num_leaves': 93, 'subsample': 0.9566561457639837, 'colsample_bytree': 0.7918727635277152, 'reg_alpha': 0.040310547309398155, 'reg_lambda': 7.147619657262334}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:45:01,612] Trial 40 finished with value: 0.9912956902361195 and parameters: {'n_estimators': 380, 'learning_rate': 0.12475307938440852, 'max_depth': 4, 'num_leaves': 87, 'subsample': 0.9701987085941997, 'colsample_bytree': 0.9976211563392188, 'reg_alpha': 9.130039228297036, 'reg_lambda': 6.538444652233352}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:45:52,584] Trial 41 finished with value: 0.9956396181267608 and parameters: {'n_estimators': 424, 'learning_rate': 0.06792651694500358, 'max_depth': 6, 'num_leaves': 94, 'subsample': 0.9532871200229471, 'colsample_bytree': 0.8061084835192409, 'reg_alpha': 0.03832369186902088, 'reg_lambda': 4.936235691155857}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:46:45,437] Trial 42 finished with value: 0.9960461138554322 and parameters: {'n_estimators': 499, 'learning_rate': 0.0768729846831846, 'max_depth': 4, 'num_leaves': 92, 'subsample': 0.9346242565466567, 'colsample_bytree': 0.7816233056552886, 'reg_alpha': 0.02465051818681536, 'reg_lambda': 1.9414570695931324}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:47:30,065] Trial 43 finished with value: 0.9955863246916044 and parameters: {'n_estimators': 292, 'learning_rate': 0.07333520490376322, 'max_depth': 7, 'num_leaves': 86, 'subsample': 0.9983143878242999, 'colsample_bytree': 0.9042393745921, 'reg_alpha': 0.06734642296066197, 'reg_lambda': 9.436451067182903}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:48:21,545] Trial 44 finished with value: 0.9963405152113699 and parameters: {'n_estimators': 487, 'learning_rate': 0.16866864490649722, 'max_depth': 5, 'num_leaves': 75, 'subsample': 0.9114133337189831, 'colsample_bytree': 0.8864846649399304, 'reg_alpha': 0.05145555715493426, 'reg_lambda': 4.832649721219697}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:49:02,125] Trial 45 finished with value: 0.9809291213395982 and parameters: {'n_estimators': 416, 'learning_rate': 0.049074550994885745, 'max_depth': 3, 'num_leaves': 59, 'subsample': 0.963355331105194, 'colsample_bytree': 0.9393593746271817, 'reg_alpha': 0.1650281818361552, 'reg_lambda': 3.1411081325498347}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:50:06,746] Trial 46 finished with value: 0.9064110391701211 and parameters: {'n_estimators': 594, 'learning_rate': 0.0010940535123577385, 'max_depth': 6, 'num_leaves': 13, 'subsample': 0.9410783895032959, 'colsample_bytree': 0.7371323318031178, 'reg_alpha': 0.013350769750088292, 'reg_lambda': 1.4999984381455838}. Best is trial 39 with value: 0.9968795765148493.\n",
      "[I 2025-05-08 16:51:08,637] Trial 47 finished with value: 0.9970415180090606 and parameters: {'n_estimators': 676, 'learning_rate': 0.1857610210604661, 'max_depth': 4, 'num_leaves': 95, 'subsample': 0.9774663263768982, 'colsample_bytree': 0.8737282919135203, 'reg_alpha': 0.09519559262569334, 'reg_lambda': 5.544416291147713}. Best is trial 47 with value: 0.9970415180090606.\n",
      "[I 2025-05-08 16:52:12,823] Trial 48 finished with value: 0.9929539608971814 and parameters: {'n_estimators': 669, 'learning_rate': 0.19280695841256928, 'max_depth': 4, 'num_leaves': 96, 'subsample': 0.501490589342601, 'colsample_bytree': 0.8705907006260138, 'reg_alpha': 0.20101600441828255, 'reg_lambda': 0.012428996635280838}. Best is trial 47 with value: 0.9970415180090606.\n",
      "[I 2025-05-08 16:53:45,980] Trial 49 finished with value: 0.9966647574372581 and parameters: {'n_estimators': 804, 'learning_rate': 0.21285270397807815, 'max_depth': 5, 'num_leaves': 83, 'subsample': 0.9816976946124677, 'colsample_bytree': 0.9264821329220901, 'reg_alpha': 1.0423332330516557, 'reg_lambda': 7.106574767192147}. Best is trial 47 with value: 0.9970415180090606.\n",
      "[I 2025-05-08 16:55:16,718] Trial 50 finished with value: 0.9975135614319525 and parameters: {'n_estimators': 856, 'learning_rate': 0.22622748221033168, 'max_depth': 5, 'num_leaves': 84, 'subsample': 0.9800466970485734, 'colsample_bytree': 0.9685490746412753, 'reg_alpha': 1.023833117079613, 'reg_lambda': 6.329200630950509}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 16:56:35,362] Trial 51 finished with value: 0.9974373105921455 and parameters: {'n_estimators': 909, 'learning_rate': 0.22371316870164532, 'max_depth': 5, 'num_leaves': 83, 'subsample': 0.9799161610713022, 'colsample_bytree': 0.9773232853960883, 'reg_alpha': 2.133807799074376, 'reg_lambda': 6.23552529170243}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 16:58:21,237] Trial 52 finished with value: 0.9974907886914071 and parameters: {'n_estimators': 906, 'learning_rate': 0.2265202401638833, 'max_depth': 5, 'num_leaves': 84, 'subsample': 0.9793949304713477, 'colsample_bytree': 0.9766920641168951, 'reg_alpha': 0.7845398795767407, 'reg_lambda': 6.378149358749325}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 16:59:28,270] Trial 53 finished with value: 0.9955174307540243 and parameters: {'n_estimators': 927, 'learning_rate': 0.2834540947820423, 'max_depth': 3, 'num_leaves': 90, 'subsample': 0.9985624666618148, 'colsample_bytree': 0.9727382373045722, 'reg_alpha': 2.6670461331539848, 'reg_lambda': 5.889857605897374}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:00:56,341] Trial 54 finished with value: 0.9963010968661882 and parameters: {'n_estimators': 918, 'learning_rate': 0.2258154194019342, 'max_depth': 4, 'num_leaves': 97, 'subsample': 0.9724249869229252, 'colsample_bytree': 0.9813658385659969, 'reg_alpha': 0.7286215531930074, 'reg_lambda': 2.4964654397751076}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:02:07,497] Trial 55 finished with value: 0.9955979026176246 and parameters: {'n_estimators': 849, 'learning_rate': 0.12935749957371717, 'max_depth': 3, 'num_leaves': 84, 'subsample': 0.9812927991594287, 'colsample_bytree': 0.8996092146351762, 'reg_alpha': 2.2892141719488395, 'reg_lambda': 7.55543482182353}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:03:15,801] Trial 56 finished with value: 0.9974775687237791 and parameters: {'n_estimators': 993, 'learning_rate': 0.167033543752131, 'max_depth': 5, 'num_leaves': 89, 'subsample': 0.9207232727327773, 'colsample_bytree': 0.9965777361505961, 'reg_alpha': 4.566238123495275, 'reg_lambda': 9.225273461504147}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:04:31,364] Trial 57 finished with value: 0.9970634012018535 and parameters: {'n_estimators': 999, 'learning_rate': 0.16811174658804923, 'max_depth': 5, 'num_leaves': 91, 'subsample': 0.921831886865065, 'colsample_bytree': 0.9986189914443065, 'reg_alpha': 5.534619258234274, 'reg_lambda': 9.94565016331205}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:05:42,251] Trial 58 finished with value: 0.9973482767144581 and parameters: {'n_estimators': 998, 'learning_rate': 0.16011768748998642, 'max_depth': 5, 'num_leaves': 89, 'subsample': 0.9280383270074124, 'colsample_bytree': 0.9898883309083178, 'reg_alpha': 5.105999214877097, 'reg_lambda': 3.5374513699356376}. Best is trial 50 with value: 0.9975135614319525.\n",
      "[I 2025-05-08 17:06:49,587] Trial 59 finished with value: 0.9971988063725574 and parameters: {'n_estimators': 989, 'learning_rate': 0.15343008595580723, 'max_depth': 5, 'num_leaves': 90, 'subsample': 0.8392617988336991, 'colsample_bytree': 0.9990788174241908, 'reg_alpha': 4.83771703474182, 'reg_lambda': 8.831350917322409}. Best is trial 50 with value: 0.9975135614319525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Evaluation Results:\n",
      "--------------------------------------------------\n",
      "CV F1: 0.9975 ± 0.0030\n",
      "Test F1: 0.8548\n",
      "Test Accuracy: 0.8818\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 17.43651819229126, 'Peak CPU (%)': 100.0, 'Avg CPU (%)': 94.97647058823527}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack       0.99      0.31      0.47   2746847\n",
      "      BENIGN       0.88      1.00      0.93  13390249\n",
      "\n",
      "    accuracy                           0.88  16137096\n",
      "   macro avg       0.93      0.65      0.70  16137096\n",
      "weighted avg       0.90      0.88      0.85  16137096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27832cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  18.106565952301025\n",
      "CV F1: 0.9974 ± 0.0031\n",
      "Test Accuracy: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack     0.9908    0.3237    0.4880   2746847\n",
      "      BENIGN     0.8781    0.9994    0.9348  13390249\n",
      "\n",
      "    accuracy                         0.8844  16137096\n",
      "   macro avg     0.9345    0.6616    0.7114  16137096\n",
      "weighted avg     0.8973    0.8844    0.8588  16137096\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 7.788529872894287, 'Peak CPU (%)': 100.0, 'Avg CPU (%)': 96.71780821917808}\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_lgbm={'n_estimators': 285, 'learning_rate': 0.15274828247019778, 'max_depth': 5, 'num_leaves': 44, 'subsample': 0.6210331060028171, 'colsample_bytree': 0.9909317475119969, 'reg_alpha': 0.4761330684134722, 'reg_lambda': 1.8813380938652553})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da65fb",
   "metadata": {},
   "source": [
    "# Binary with cross-val on single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb5912",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15c1fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2472174679.py:2: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  df = pd.read_csv(\"..\\cicids2018_training.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2018_training.csv\")\n",
    "\n",
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d640541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c44249df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a126faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f75f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37165324",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2018 = {\n",
    "    'Normal Traffic': 'BENIGN',\n",
    "    'DoS': 'Attack',\n",
    "    'DDoS': 'Attack',\n",
    "    'Brute Force': 'Attack',\n",
    "    'Bot': 'Attack',\n",
    "    'Infilteration': 'Attack'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ed72be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2018)\n",
    "y_test = y_test.map(group_mapping_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b619770",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 17:19:27,084] A new study created in memory with name: no-name-ca30a774-9e69-4742-8e88-1da0b89a4147\n",
      "[I 2025-05-08 17:20:06,623] Trial 0 finished with value: 0.9984349205058625 and parameters: {'n_estimators': 383, 'learning_rate': 0.12111930457526512, 'max_depth': 3, 'num_leaves': 91, 'subsample': 0.5835162686194524, 'colsample_bytree': 0.6888231079926798, 'reg_alpha': 0.05721460438284763, 'reg_lambda': 0.001587734342698104}. Best is trial 0 with value: 0.9984349205058625.\n",
      "[I 2025-05-08 17:21:30,157] Trial 1 finished with value: 0.9980886755221992 and parameters: {'n_estimators': 332, 'learning_rate': 0.009589780908912389, 'max_depth': 15, 'num_leaves': 96, 'subsample': 0.5405799783730312, 'colsample_bytree': 0.7626151265013338, 'reg_alpha': 1.9556808899672304, 'reg_lambda': 1.403980100280639}. Best is trial 0 with value: 0.9984349205058625.\n",
      "[I 2025-05-08 17:22:24,576] Trial 2 finished with value: 0.998981839357992 and parameters: {'n_estimators': 437, 'learning_rate': 0.13041809265941273, 'max_depth': 9, 'num_leaves': 24, 'subsample': 0.6145425539179735, 'colsample_bytree': 0.7925553001021364, 'reg_alpha': 0.009522964398446345, 'reg_lambda': 0.11778437294592758}. Best is trial 2 with value: 0.998981839357992.\n",
      "[I 2025-05-08 17:23:37,078] Trial 3 finished with value: 0.9990572697552725 and parameters: {'n_estimators': 296, 'learning_rate': 0.037904838739522134, 'max_depth': 13, 'num_leaves': 97, 'subsample': 0.7624282654375554, 'colsample_bytree': 0.6474740382404801, 'reg_alpha': 0.007943263066180881, 'reg_lambda': 0.003233019448981201}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:25:29,518] Trial 4 finished with value: 0.9989100281807003 and parameters: {'n_estimators': 694, 'learning_rate': 0.08289289897367737, 'max_depth': 11, 'num_leaves': 39, 'subsample': 0.9761432516526902, 'colsample_bytree': 0.8715042741892618, 'reg_alpha': 0.018115204072327567, 'reg_lambda': 1.2293304993584602}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:26:46,330] Trial 5 finished with value: 0.9989655114283267 and parameters: {'n_estimators': 701, 'learning_rate': 0.0758359325114676, 'max_depth': 11, 'num_leaves': 65, 'subsample': 0.5799160834922683, 'colsample_bytree': 0.5934238387890569, 'reg_alpha': 4.349166737458315, 'reg_lambda': 0.0643776992264372}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:27:06,346] Trial 6 finished with value: 0.998861896850322 and parameters: {'n_estimators': 75, 'learning_rate': 0.2796682629076551, 'max_depth': 12, 'num_leaves': 96, 'subsample': 0.9997795844893657, 'colsample_bytree': 0.9990337392865578, 'reg_alpha': 0.014602386606994857, 'reg_lambda': 0.07120641782771862}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:29:06,682] Trial 7 finished with value: 0.9989782457331511 and parameters: {'n_estimators': 837, 'learning_rate': 0.028145135294834246, 'max_depth': 6, 'num_leaves': 98, 'subsample': 0.646844710821489, 'colsample_bytree': 0.948820386419355, 'reg_alpha': 0.1430398648703098, 'reg_lambda': 0.08916133381667747}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:29:33,416] Trial 8 finished with value: 0.9976459389062178 and parameters: {'n_estimators': 128, 'learning_rate': 0.019539268612370694, 'max_depth': 13, 'num_leaves': 81, 'subsample': 0.7232932782401702, 'colsample_bytree': 0.6768548767664428, 'reg_alpha': 0.08146217774744058, 'reg_lambda': 0.06717235316346522}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:31:33,572] Trial 9 finished with value: 0.9941698213038684 and parameters: {'n_estimators': 674, 'learning_rate': 0.002453403310002812, 'max_depth': 14, 'num_leaves': 67, 'subsample': 0.9766513372761265, 'colsample_bytree': 0.7607601820582459, 'reg_alpha': 0.1026801228676751, 'reg_lambda': 0.20793689943015456}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:32:14,032] Trial 10 finished with value: 0.9752217044541392 and parameters: {'n_estimators': 252, 'learning_rate': 0.0010881295161010154, 'max_depth': 8, 'num_leaves': 45, 'subsample': 0.8511395560587901, 'colsample_bytree': 0.5042323574255128, 'reg_alpha': 0.0012350687839060206, 'reg_lambda': 0.001850399825920212}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:33:15,165] Trial 11 finished with value: 0.998565805923282 and parameters: {'n_estimators': 490, 'learning_rate': 0.033977328472625704, 'max_depth': 8, 'num_leaves': 13, 'subsample': 0.7481112104756535, 'colsample_bytree': 0.8513308767351333, 'reg_alpha': 0.0015779337745041964, 'reg_lambda': 0.020648063363267046}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:34:09,124] Trial 12 finished with value: 0.9944433368710559 and parameters: {'n_estimators': 494, 'learning_rate': 0.2967431728887419, 'max_depth': 10, 'num_leaves': 11, 'subsample': 0.8467958932414571, 'colsample_bytree': 0.6238256952192109, 'reg_alpha': 0.005064250616100577, 'reg_lambda': 0.0075124915601698285}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:34:47,659] Trial 13 finished with value: 0.9826796494418257 and parameters: {'n_estimators': 236, 'learning_rate': 0.005912064826520008, 'max_depth': 6, 'num_leaves': 30, 'subsample': 0.6544295049862289, 'colsample_bytree': 0.8374193035153927, 'reg_alpha': 0.006999107107618014, 'reg_lambda': 7.158835777149187}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:36:40,840] Trial 14 finished with value: 0.9989391318759496 and parameters: {'n_estimators': 995, 'learning_rate': 0.058634129269198317, 'max_depth': 9, 'num_leaves': 24, 'subsample': 0.8226607771027624, 'colsample_bytree': 0.5483732163543295, 'reg_alpha': 1.0011987239319458, 'reg_lambda': 0.008200498885007425}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:37:47,484] Trial 15 finished with value: 0.9989127624712065 and parameters: {'n_estimators': 418, 'learning_rate': 0.14935349597671072, 'max_depth': 6, 'num_leaves': 58, 'subsample': 0.6653983178343411, 'colsample_bytree': 0.7052605974413098, 'reg_alpha': 0.02308688598583235, 'reg_lambda': 0.3613167928308974}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:39:49,965] Trial 16 finished with value: 0.9988129159761134 and parameters: {'n_estimators': 579, 'learning_rate': 0.010077915382389273, 'max_depth': 13, 'num_leaves': 77, 'subsample': 0.7976139363360543, 'colsample_bytree': 0.7936322546897665, 'reg_alpha': 0.4584367026327425, 'reg_lambda': 0.01611627984724096}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:40:11,375] Trial 17 finished with value: 0.986639407751092 and parameters: {'n_estimators': 211, 'learning_rate': 0.04509850323955549, 'max_depth': 3, 'num_leaves': 48, 'subsample': 0.8982452696323311, 'colsample_bytree': 0.6285231137518711, 'reg_alpha': 0.0037286986124248638, 'reg_lambda': 0.0038873897458967348}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:40:58,494] Trial 18 finished with value: 0.9990336329878831 and parameters: {'n_estimators': 325, 'learning_rate': 0.12682796072104457, 'max_depth': 15, 'num_leaves': 25, 'subsample': 0.5108197225987132, 'colsample_bytree': 0.9203255036858999, 'reg_alpha': 0.033606963246739875, 'reg_lambda': 0.5744295198129925}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:42:02,211] Trial 19 finished with value: 0.9987620420652761 and parameters: {'n_estimators': 330, 'learning_rate': 0.016854105147960693, 'max_depth': 15, 'num_leaves': 83, 'subsample': 0.505931216766897, 'colsample_bytree': 0.9125932791870086, 'reg_alpha': 0.3613836974301384, 'reg_lambda': 0.6790992276091076}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:42:29,022] Trial 20 finished with value: 0.9990136587888424 and parameters: {'n_estimators': 146, 'learning_rate': 0.1851446096572942, 'max_depth': 13, 'num_leaves': 36, 'subsample': 0.7091782739663879, 'colsample_bytree': 0.9848207272398393, 'reg_alpha': 0.03518724494449093, 'reg_lambda': 4.718929351596237}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:42:56,518] Trial 21 finished with value: 0.9990054865229553 and parameters: {'n_estimators': 155, 'learning_rate': 0.17956850192260604, 'max_depth': 14, 'num_leaves': 35, 'subsample': 0.7105877719022101, 'colsample_bytree': 0.9995431883458087, 'reg_alpha': 0.05230514759589133, 'reg_lambda': 7.190628265721806}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:43:11,170] Trial 22 finished with value: 0.996886176806246 and parameters: {'n_estimators': 62, 'learning_rate': 0.08542962031572572, 'max_depth': 13, 'num_leaves': 24, 'subsample': 0.9071318129040193, 'colsample_bytree': 0.9341924195761983, 'reg_alpha': 0.03264822907851518, 'reg_lambda': 3.187368165383616}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:44:00,821] Trial 23 finished with value: 0.9988700490553128 and parameters: {'n_estimators': 321, 'learning_rate': 0.22322583286336184, 'max_depth': 14, 'num_leaves': 54, 'subsample': 0.7954672703568209, 'colsample_bytree': 0.9045892347263356, 'reg_alpha': 0.002875854967061631, 'reg_lambda': 2.6797283314782567}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:44:35,325] Trial 24 finished with value: 0.9986184614974765 and parameters: {'n_estimators': 180, 'learning_rate': 0.04693872669578553, 'max_depth': 12, 'num_leaves': 40, 'subsample': 0.688347490936495, 'colsample_bytree': 0.9599554061133576, 'reg_alpha': 0.22451863733900373, 'reg_lambda': 0.4263638136777224}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:45:18,440] Trial 25 finished with value: 0.9990536295458007 and parameters: {'n_estimators': 272, 'learning_rate': 0.11719770791459076, 'max_depth': 15, 'num_leaves': 33, 'subsample': 0.7757942526244502, 'colsample_bytree': 0.9685702102055928, 'reg_alpha': 0.0315549280467293, 'reg_lambda': 2.3639339175305376}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:46:21,747] Trial 26 finished with value: 0.9990181973801613 and parameters: {'n_estimators': 569, 'learning_rate': 0.10133214735877233, 'max_depth': 15, 'num_leaves': 18, 'subsample': 0.7585248175473326, 'colsample_bytree': 0.8870852216572198, 'reg_alpha': 0.010890077497085138, 'reg_lambda': 0.8197744969383786}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:47:12,334] Trial 27 finished with value: 0.9989055810575813 and parameters: {'n_estimators': 282, 'learning_rate': 0.030764211251087473, 'max_depth': 15, 'num_leaves': 50, 'subsample': 0.7582071132676389, 'colsample_bytree': 0.7184914035537657, 'reg_alpha': 0.0020028589999173717, 'reg_lambda': 0.2401602245020443}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:48:22,208] Trial 28 finished with value: 0.9990282032379101 and parameters: {'n_estimators': 417, 'learning_rate': 0.06045032097240314, 'max_depth': 14, 'num_leaves': 29, 'subsample': 0.9056709185037222, 'colsample_bytree': 0.8207055194355242, 'reg_alpha': 0.006301844932717944, 'reg_lambda': 2.195943076735215}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:49:19,556] Trial 29 finished with value: 0.9987419365054793 and parameters: {'n_estimators': 384, 'learning_rate': 0.13122498065298546, 'max_depth': 12, 'num_leaves': 70, 'subsample': 0.7982867073930122, 'colsample_bytree': 0.6486126394616821, 'reg_alpha': 0.0651823341761521, 'reg_lambda': 0.026041960853475012}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:50:15,246] Trial 30 finished with value: 0.9987229379644221 and parameters: {'n_estimators': 307, 'learning_rate': 0.021468397503402608, 'max_depth': 15, 'num_leaves': 60, 'subsample': 0.8767119456481189, 'colsample_bytree': 0.5873803829748082, 'reg_alpha': 0.03688699627579472, 'reg_lambda': 0.0010983342018921842}. Best is trial 3 with value: 0.9990572697552725.\n",
      "[I 2025-05-08 17:51:28,630] Trial 31 finished with value: 0.9990663657937559 and parameters: {'n_estimators': 428, 'learning_rate': 0.05609120350998945, 'max_depth': 14, 'num_leaves': 30, 'subsample': 0.9496611358612602, 'colsample_bytree': 0.8260987348910772, 'reg_alpha': 0.004582344764716212, 'reg_lambda': 2.1042040654670107}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:52:23,427] Trial 32 finished with value: 0.9988855927961012 and parameters: {'n_estimators': 362, 'learning_rate': 0.05506051392514812, 'max_depth': 14, 'num_leaves': 18, 'subsample': 0.592592732883143, 'colsample_bytree': 0.9270877884996159, 'reg_alpha': 0.01705006466477303, 'reg_lambda': 1.4782705825554654}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:53:38,594] Trial 33 finished with value: 0.9989409394719786 and parameters: {'n_estimators': 456, 'learning_rate': 0.10978547783448207, 'max_depth': 15, 'num_leaves': 32, 'subsample': 0.9439244599824198, 'colsample_bytree': 0.7383537599437024, 'reg_alpha': 0.002560912200514859, 'reg_lambda': 0.7354120889806847}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:54:45,514] Trial 34 finished with value: 0.9987674865287801 and parameters: {'n_estimators': 370, 'learning_rate': 0.042207958372785515, 'max_depth': 11, 'num_leaves': 19, 'subsample': 0.5383453054362973, 'colsample_bytree': 0.8789205529067438, 'reg_alpha': 0.009341674398075478, 'reg_lambda': 1.6496593856333304}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:56:24,342] Trial 35 finished with value: 0.9990072824795945 and parameters: {'n_estimators': 576, 'learning_rate': 0.07602174796160896, 'max_depth': 13, 'num_leaves': 42, 'subsample': 0.6205042127475584, 'colsample_bytree': 0.7916418873521559, 'reg_alpha': 0.02205137319605642, 'reg_lambda': 4.513261653435273}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:57:24,382] Trial 36 finished with value: 0.9979124108130961 and parameters: {'n_estimators': 274, 'learning_rate': 0.011894005979492712, 'max_depth': 14, 'num_leaves': 92, 'subsample': 0.9362520217046318, 'colsample_bytree': 0.8553020827518576, 'reg_alpha': 0.004117067846538571, 'reg_lambda': 9.64757448798699}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:58:04,828] Trial 37 finished with value: 0.9990427438043508 and parameters: {'n_estimators': 212, 'learning_rate': 0.11266407212969361, 'max_depth': 12, 'num_leaves': 25, 'subsample': 0.5568254045405086, 'colsample_bytree': 0.9484952355642648, 'reg_alpha': 0.011481805926206689, 'reg_lambda': 0.13882792692305146}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:58:29,938] Trial 38 finished with value: 0.9986130239408049 and parameters: {'n_estimators': 116, 'learning_rate': 0.07290872299085746, 'max_depth': 12, 'num_leaves': 36, 'subsample': 0.5802938889325728, 'colsample_bytree': 0.8109353991537444, 'reg_alpha': 0.011508207268248067, 'reg_lambda': 0.04270139393505842}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 17:59:11,893] Trial 39 finished with value: 0.9927675693300392 and parameters: {'n_estimators': 204, 'learning_rate': 0.005447075166771698, 'max_depth': 11, 'num_leaves': 88, 'subsample': 0.7382801100873804, 'colsample_bytree': 0.9651098042973347, 'reg_alpha': 7.97322366819906, 'reg_lambda': 0.1205818851347225}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:00:03,352] Trial 40 finished with value: 0.998665747415276 and parameters: {'n_estimators': 255, 'learning_rate': 0.025913882239235023, 'max_depth': 10, 'num_leaves': 72, 'subsample': 0.7827170961701637, 'colsample_bytree': 0.672037232151983, 'reg_alpha': 0.007426351392706673, 'reg_lambda': 0.20199683240327604}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:00:55,278] Trial 41 finished with value: 0.9990436450186456 and parameters: {'n_estimators': 348, 'learning_rate': 0.10258965989048663, 'max_depth': 15, 'num_leaves': 24, 'subsample': 0.5468512039720531, 'colsample_bytree': 0.968315205315728, 'reg_alpha': 0.01461502567137629, 'reg_lambda': 1.0721561234872174}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:02:01,322] Trial 42 finished with value: 0.99904091089075 and parameters: {'n_estimators': 453, 'learning_rate': 0.09148002701648111, 'max_depth': 13, 'num_leaves': 27, 'subsample': 0.5519731658547525, 'colsample_bytree': 0.9732520560818769, 'reg_alpha': 0.015641103793241556, 'reg_lambda': 1.0025328462531389}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:03:03,727] Trial 43 finished with value: 0.9986284841013076 and parameters: {'n_estimators': 390, 'learning_rate': 0.03847567445772793, 'max_depth': 12, 'num_leaves': 16, 'subsample': 0.6216029000395389, 'colsample_bytree': 0.9496314843191185, 'reg_alpha': 0.0011129405250233583, 'reg_lambda': 3.665533591266862}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:04:06,028] Trial 44 finished with value: 0.9988900451670892 and parameters: {'n_estimators': 516, 'learning_rate': 0.20144788981136327, 'max_depth': 14, 'num_leaves': 21, 'subsample': 0.6812754559404818, 'colsample_bytree': 0.8869946303125602, 'reg_alpha': 0.11684472175001345, 'reg_lambda': 1.767629763301752}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:04:24,509] Trial 45 finished with value: 0.9908056957503216 and parameters: {'n_estimators': 107, 'learning_rate': 0.07087544507106852, 'max_depth': 13, 'num_leaves': 10, 'subsample': 0.5542842624844214, 'colsample_bytree': 0.943299948646789, 'reg_alpha': 0.012203634542831493, 'reg_lambda': 0.12945080822084362}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:05:04,554] Trial 46 finished with value: 0.9969342559076763 and parameters: {'n_estimators': 208, 'learning_rate': 0.16498593241970588, 'max_depth': 11, 'num_leaves': 34, 'subsample': 0.8479798571536932, 'colsample_bytree': 0.9823392416000967, 'reg_alpha': 0.005363435396658366, 'reg_lambda': 0.0027733854888527865}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:06:31,844] Trial 47 finished with value: 0.9988337055344578 and parameters: {'n_estimators': 646, 'learning_rate': 0.10915698537869448, 'max_depth': 15, 'num_leaves': 44, 'subsample': 0.5930461525478177, 'colsample_bytree': 0.9001073488924849, 'reg_alpha': 0.0537547628001, 'reg_lambda': 0.3130938439136626}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:08:25,251] Trial 48 finished with value: 0.9786383558722805 and parameters: {'n_estimators': 832, 'learning_rate': 0.2437166421848568, 'max_depth': 14, 'num_leaves': 28, 'subsample': 0.637110926097414, 'colsample_bytree': 0.8598620263070849, 'reg_alpha': 0.0032974138513568157, 'reg_lambda': 0.01079612963435106}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:09:11,008] Trial 49 finished with value: 0.997282415262233 and parameters: {'n_estimators': 282, 'learning_rate': 0.056361508454850724, 'max_depth': 4, 'num_leaves': 14, 'subsample': 0.9952289234766694, 'colsample_bytree': 0.5760875293715731, 'reg_alpha': 0.0018658304543885814, 'reg_lambda': 1.1446313866202449}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:10:03,801] Trial 50 finished with value: 0.9989373025753882 and parameters: {'n_estimators': 355, 'learning_rate': 0.13759767749238747, 'max_depth': 10, 'num_leaves': 38, 'subsample': 0.8197980851479643, 'colsample_bytree': 0.7459782952991395, 'reg_alpha': 0.021366583597302667, 'reg_lambda': 0.5153360540846768}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:11:09,712] Trial 51 finished with value: 0.9990427230741888 and parameters: {'n_estimators': 415, 'learning_rate': 0.08930133788357413, 'max_depth': 13, 'num_leaves': 27, 'subsample': 0.5461618143097963, 'colsample_bytree': 0.9787388753681537, 'reg_alpha': 0.007997317519118736, 'reg_lambda': 1.119975607814238}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:12:02,689] Trial 52 finished with value: 0.9990218255438069 and parameters: {'n_estimators': 423, 'learning_rate': 0.09983956355821993, 'max_depth': 12, 'num_leaves': 22, 'subsample': 0.5483465712231788, 'colsample_bytree': 0.986557804238478, 'reg_alpha': 0.007902662468967297, 'reg_lambda': 0.03999008076557485}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:12:42,715] Trial 53 finished with value: 0.9989809807907755 and parameters: {'n_estimators': 250, 'learning_rate': 0.06109505224902794, 'max_depth': 13, 'num_leaves': 31, 'subsample': 0.5273974322664712, 'colsample_bytree': 0.957008501401439, 'reg_alpha': 0.005813991957323458, 'reg_lambda': 2.3733224205434915}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:13:48,463] Trial 54 finished with value: 0.9989836608433051 and parameters: {'n_estimators': 486, 'learning_rate': 0.1447098771818662, 'max_depth': 14, 'num_leaves': 26, 'subsample': 0.5239779487605545, 'colsample_bytree': 0.9331549933825604, 'reg_alpha': 0.02790723239215437, 'reg_lambda': 6.008565211773403}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:15:00,253] Trial 55 finished with value: 0.998978248277431 and parameters: {'n_estimators': 541, 'learning_rate': 0.03648665471274866, 'max_depth': 15, 'num_leaves': 22, 'subsample': 0.8219642676240673, 'colsample_bytree': 0.7767259354149891, 'reg_alpha': 0.014689170470941378, 'reg_lambda': 0.004028613000104583}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:15:47,654] Trial 56 finished with value: 0.9843198087464259 and parameters: {'n_estimators': 300, 'learning_rate': 0.0010112296565496688, 'max_depth': 8, 'num_leaves': 47, 'subsample': 0.5672060048561828, 'colsample_bytree': 0.9990580597704792, 'reg_alpha': 0.0043807156966704985, 'reg_lambda': 1.3898019180612295}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:16:15,063] Trial 57 finished with value: 0.9985148971983703 and parameters: {'n_estimators': 171, 'learning_rate': 0.0471905249241051, 'max_depth': 13, 'num_leaves': 33, 'subsample': 0.6055825567455948, 'colsample_bytree': 0.5197334839779606, 'reg_alpha': 0.008482735570458439, 'reg_lambda': 1.0068599625929653}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:17:26,307] Trial 58 finished with value: 0.998984607703347 and parameters: {'n_estimators': 406, 'learning_rate': 0.02487276099267729, 'max_depth': 14, 'num_leaves': 62, 'subsample': 0.8788960035092789, 'colsample_bytree': 0.9147509675608299, 'reg_alpha': 0.07643058251452858, 'reg_lambda': 0.15852187270402576}. Best is trial 31 with value: 0.9990663657937559.\n",
      "[I 2025-05-08 18:18:28,057] Trial 59 finished with value: 0.9989118563919354 and parameters: {'n_estimators': 351, 'learning_rate': 0.08801859571052599, 'max_depth': 15, 'num_leaves': 99, 'subsample': 0.7721448475252133, 'colsample_bytree': 0.8382022733850528, 'reg_alpha': 0.002466409936785929, 'reg_lambda': 2.0280058801861163}. Best is trial 31 with value: 0.9990663657937559.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM Evaluation Results:\n",
      "--------------------------------------------------\n",
      "CV F1: 0.9991 ± 0.0003\n",
      "Test F1: 0.9990\n",
      "Test Accuracy: 0.9990\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 11.896596431732178, 'Peak CPU (%)': 98.3, 'Avg CPU (%)': 92.89913793103446}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Attack       0.99      1.00      1.00    127708\n",
      "      BENIGN       1.00      1.00      1.00    628518\n",
      "\n",
      "    accuracy                           1.00    756226\n",
      "   macro avg       1.00      1.00      1.00    756226\n",
      "weighted avg       1.00      1.00      1.00    756226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d4169c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ Full error traceback:\n",
      "Error during Random Forest training: Input contains NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2897538565.py\", line 22, in apply_rf\n",
      "    train_model()\n",
      "  File \"C:\\Users\\ogoreltsev.pav\\AppData\\Local\\Temp\\ipykernel_14632\\2897538565.py\", line 15, in train_model\n",
      "    rf_model.fit(X_train, y_train)\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 360, in fit\n",
      "    X, y = validate_data(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1387, in check_X_y\n",
      "    y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1397, in _check_y\n",
      "    y = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\ML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 105, in _assert_all_finite\n",
      "    raise ValueError(\"Input contains NaN\")\n",
      "ValueError: Input contains NaN\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43meval_dataset_w_RF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_rf\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mn_estimators\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m115\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_depth\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin_samples_split\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin_samples_leaf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_features\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36meval_dataset_w_RF\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, params_rf)\u001b[39m\n\u001b[32m      5\u001b[39m start_time = time.time()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Making predictions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m y_pred_rf = \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m(X_test)\n\u001b[32m     10\u001b[39m training_time = time.time() - start_time\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPredict Time (s) - \u001b[39m\u001b[33m\"\u001b[39m, training_time)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_rf={'n_estimators': 115, 'max_depth': 30, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a070b",
   "metadata": {},
   "source": [
    "# MultiClass with cross-val between datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66ea4d",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e21116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2018_training.csv\")\n",
    "\n",
    "X_train = df.drop('Attack Type', axis=1)\n",
    "y_train = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99372926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\cicids2017_test_of_2018.csv\")\n",
    "\n",
    "X_test = df.drop('Attack Type', axis=1)\n",
    "y_test = df['Attack Type']\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93751669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de639e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_rus, y_train_resampled_rus = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd249f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping_2018 = {\n",
    "    'Normal Traffic': 'Normal Traffic',\n",
    "    'DoS': 'DoS',\n",
    "    'DDoS': 'DDoS',\n",
    "    'Brute Force': 'Brute Force',\n",
    "    'Bot': 'Bots',\n",
    "    'Infilteration': 'Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled_MMS_SMOTE = y_train_resampled_scaled_MMS_SMOTE.map(group_mapping_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5bba0",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbfcf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-08 18:22:47,278] A new study created in memory with name: no-name-41646ae6-e686-4cd8-8672-c43f676f32f9\n",
      "[I 2025-05-08 18:25:19,753] Trial 0 finished with value: 0.9773941901396974 and parameters: {'n_estimators': 292, 'learning_rate': 0.009817646069583031, 'max_depth': 10, 'num_leaves': 17, 'subsample': 0.9975221533290692, 'colsample_bytree': 0.506685846212074, 'reg_alpha': 0.4110947731660012, 'reg_lambda': 0.0011018990142059504}. Best is trial 0 with value: 0.9773941901396974.\n",
      "[I 2025-05-08 18:29:46,996] Trial 1 finished with value: 0.9763116617159586 and parameters: {'n_estimators': 389, 'learning_rate': 0.005558281677372325, 'max_depth': 11, 'num_leaves': 85, 'subsample': 0.9706927476707258, 'colsample_bytree': 0.9667394297939542, 'reg_alpha': 0.05879130150671738, 'reg_lambda': 0.3880107868025716}. Best is trial 0 with value: 0.9773941901396974.\n",
      "[I 2025-05-08 18:35:03,793] Trial 2 finished with value: 0.9860617839709296 and parameters: {'n_estimators': 699, 'learning_rate': 0.0684433928303, 'max_depth': 3, 'num_leaves': 39, 'subsample': 0.5425336490895074, 'colsample_bytree': 0.8421526656319593, 'reg_alpha': 0.1164696249778467, 'reg_lambda': 0.022144548638954896}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:42:27,817] Trial 3 finished with value: 0.9757769947659151 and parameters: {'n_estimators': 704, 'learning_rate': 0.001611119830870556, 'max_depth': 14, 'num_leaves': 50, 'subsample': 0.6701290122588083, 'colsample_bytree': 0.7149828007209887, 'reg_alpha': 0.024934158450031982, 'reg_lambda': 0.003825002286116343}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:45:17,808] Trial 4 finished with value: 0.9262459782324999 and parameters: {'n_estimators': 279, 'learning_rate': 0.0012395623455427934, 'max_depth': 15, 'num_leaves': 39, 'subsample': 0.7956939331055778, 'colsample_bytree': 0.8261463810540675, 'reg_alpha': 0.027332577182604772, 'reg_lambda': 0.08473367118346115}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:45:54,783] Trial 5 finished with value: 0.9581710230354332 and parameters: {'n_estimators': 53, 'learning_rate': 0.018111441802638628, 'max_depth': 6, 'num_leaves': 88, 'subsample': 0.9695309536670853, 'colsample_bytree': 0.6765193752828512, 'reg_alpha': 0.028305604785972754, 'reg_lambda': 0.005103129438174262}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:53:22,731] Trial 6 finished with value: 0.9577450332426796 and parameters: {'n_estimators': 962, 'learning_rate': 0.001066407515358132, 'max_depth': 6, 'num_leaves': 15, 'subsample': 0.8673871041988742, 'colsample_bytree': 0.513267787037154, 'reg_alpha': 0.07728862060365572, 'reg_lambda': 0.19060467588076227}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 18:55:36,285] Trial 7 finished with value: 0.7708616167692827 and parameters: {'n_estimators': 269, 'learning_rate': 0.2628988302471623, 'max_depth': 15, 'num_leaves': 86, 'subsample': 0.5548417415885133, 'colsample_bytree': 0.6289470215920411, 'reg_alpha': 0.056436042694506465, 'reg_lambda': 0.056165073757315276}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 19:06:09,288] Trial 8 finished with value: 0.9858216468310761 and parameters: {'n_estimators': 982, 'learning_rate': 0.027078122031015762, 'max_depth': 10, 'num_leaves': 59, 'subsample': 0.9840519831401184, 'colsample_bytree': 0.5784119420527252, 'reg_alpha': 0.3026340927319158, 'reg_lambda': 0.36576623390728513}. Best is trial 2 with value: 0.9860617839709296.\n",
      "[I 2025-05-08 19:15:22,378] Trial 9 finished with value: 0.9865435195521494 and parameters: {'n_estimators': 782, 'learning_rate': 0.17020900593347912, 'max_depth': 9, 'num_leaves': 31, 'subsample': 0.6804410895439533, 'colsample_bytree': 0.9448604525697095, 'reg_alpha': 0.0011270587279211745, 'reg_lambda': 7.867365972878037}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:24:21,940] Trial 10 finished with value: 0.9855215771339211 and parameters: {'n_estimators': 736, 'learning_rate': 0.2915765472218258, 'max_depth': 7, 'num_leaves': 64, 'subsample': 0.6511960050774539, 'colsample_bytree': 0.9800637418578985, 'reg_alpha': 0.0014472611044288866, 'reg_lambda': 8.964024981156964}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:30:14,318] Trial 11 finished with value: 0.9860966558106672 and parameters: {'n_estimators': 731, 'learning_rate': 0.07700430739175954, 'max_depth': 4, 'num_leaves': 33, 'subsample': 0.5022090663408085, 'colsample_bytree': 0.8400971071299045, 'reg_alpha': 4.47668651721483, 'reg_lambda': 9.211542196424242}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:36:20,259] Trial 12 finished with value: 0.9841640489474228 and parameters: {'n_estimators': 837, 'learning_rate': 0.08557525688869995, 'max_depth': 3, 'num_leaves': 27, 'subsample': 0.6535301192140077, 'colsample_bytree': 0.8727019096261663, 'reg_alpha': 5.966290613905174, 'reg_lambda': 6.6461524828236715}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[I 2025-05-08 19:43:37,676] Trial 13 finished with value: 0.9858034413238714 and parameters: {'n_estimators': 592, 'learning_rate': 0.0768596959339251, 'max_depth': 8, 'num_leaves': 31, 'subsample': 0.5218455259221572, 'colsample_bytree': 0.9083261098387785, 'reg_alpha': 0.0021290970729564247, 'reg_lambda': 1.7053953258444798}. Best is trial 9 with value: 0.9865435195521494.\n",
      "[W 2025-05-08 19:43:53,580] Trial 14 failed with parameters: {'n_estimators': 546, 'learning_rate': 0.1351623352688896, 'max_depth': 12, 'num_leaves': 47, 'subsample': 0.7412734737535848, 'colsample_bytree': 0.7850647643174222, 'reg_alpha': 8.027291555723322, 'reg_lambda': 1.5897804036549203} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_32996\\3452006036.py\", line 17, in objective\n",
      "    cv_scores, _, model = apply_lgbm(X_train, y_train, best_params=params, cv=cv)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Pavel\\AppData\\Local\\Temp\\ipykernel_32996\\839345318.py\", line 19, in apply_lgbm\n",
      "    lgbm_model.fit(X_train, y_train)\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1560, in fit\n",
      "    super().fit(\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-08 19:43:53,592] Trial 14 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lbgm_model, best_params = \u001b[43mshow_results_LGBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mX_test_MMS_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_train_resampled_scaled_MMS_SMOTE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                                    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mshow_results_LGBM\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, n_trials)\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores) \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     20\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m best_params = study.best_params\n\u001b[32m     24\u001b[39m cv_scores_lgbm, measurement_lgbm, lgbm_model = apply_lgbm(X_train, y_train, best_params=best_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mshow_results_LGBM.<locals>.objective\u001b[39m\u001b[34m(trial, X_train, y_train, cv)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective\u001b[39m(trial, X_train, y_train, cv=\u001b[32m5\u001b[39m):\n\u001b[32m      6\u001b[39m     params = {\n\u001b[32m      7\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_int(\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1000\u001b[39m),\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-3\u001b[39m, \u001b[32m0.3\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m: trial.suggest_float(\u001b[33m'\u001b[39m\u001b[33mreg_lambda\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m1e-3\u001b[39m, \u001b[32m10.0\u001b[39m, log=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     cv_scores, _, model = \u001b[43mapply_lgbm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(cv_scores) \u001b[38;5;28;01mif\u001b[39;00m cv_scores \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mapply_lgbm\u001b[39m\u001b[34m(X_train, y_train, best_params, n_jobs, cv)\u001b[39m\n\u001b[32m     16\u001b[39m cpu_thread.start()\n\u001b[32m     17\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mlgbm_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m training_time = time.time() - start_time\n\u001b[32m     22\u001b[39m stop_flag.set()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py:1560\u001b[39m, in \u001b[36mLGBMClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1557\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1558\u001b[39m             valid_sets.append((valid_x, \u001b[38;5;28mself\u001b[39m._le.transform(valid_y)))\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1573\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1574\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1575\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rf_model, best_params = show_results(X_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    X_test_MMS_scaled,\n",
    "                                    y_train_resampled_scaled_MMS_SMOTE, \n",
    "                                    y_test, \n",
    "                                    n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadcdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Time (s) -  449.11964774131775\n",
      "CV F1: 0.9865 ± 0.0250\n",
      "Test Accuracy: 0.8664\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          Bots     0.9995    0.0269    0.0525    286191\n",
      "   Brute Force     0.9807    0.4131    0.5813    381784\n",
      "          DDoS     1.0000    0.0010    0.0019   1263933\n",
      "           DoS     0.9933    0.7062    0.8255    654300\n",
      "Normal Traffic     0.8834    0.9952    0.9360  13390249\n",
      "         Other     0.0611    0.1587    0.0883    160639\n",
      "\n",
      "      accuracy                         0.8664  16137096\n",
      "     macro avg     0.8197    0.3835    0.4142  16137096\n",
      "  weighted avg     0.8932    0.8664    0.8258  16137096\n",
      "\n",
      "Resource Usage: {'Training Time (s)': 107.71467423439026, 'Peak CPU (%)': 100.0, 'Avg CPU (%)': 97.70577651515151}\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test, params_lgbm={'n_estimators': 782, 'learning_rate': 0.17020900593347912, 'max_depth': 9, 'num_leaves': 31, 'subsample': 0.6804410895439533, 'colsample_bytree': 0.9448604525697095, 'reg_alpha': 0.0011270587279211745, 'reg_lambda': 7.867365972878037})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
