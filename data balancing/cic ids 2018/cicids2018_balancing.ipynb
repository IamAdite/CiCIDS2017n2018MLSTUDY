{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f86f9b4",
   "metadata": {},
   "source": [
    "# Imports and benchmark functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e45e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import threading\n",
    "from memory_profiler import memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f74d9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rf(X_train, y_train, best_params=None, random_state=42, n_jobs=-1, cv=5): \n",
    "    measurement_rf = {}\n",
    "        \n",
    "    # Default to empty dictionary if best_params is not provided\n",
    "    best_params = best_params or {}\n",
    "\n",
    "    rf_model = RandomForestClassifier(**best_params, random_state=random_state, n_jobs=n_jobs, verbose=1)\n",
    "    \n",
    "    # Function to monitor CPU usage during training\n",
    "    cpu_usage = []\n",
    "    stop_flag = threading.Event()\n",
    "\n",
    "    def monitor_cpu():\n",
    "        while not stop_flag.is_set():\n",
    "            cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "\n",
    "    # Function to train the model\n",
    "    def train_model():\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "    try:\n",
    "        # Start CPU monitoring in a separate thread\n",
    "        cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "        cpu_thread.start()\n",
    "\n",
    "        # Measure memory usage and training time\n",
    "        start_time = time.time()\n",
    "        train_model()\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Stop CPU monitoring\n",
    "        stop_flag.set()\n",
    "        cpu_thread.join()\n",
    "\n",
    "        # Add measurements\n",
    "        measurement_rf['Training Time (s)'] = training_time\n",
    "        measurement_rf['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "        measurement_rf['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "\n",
    "        # Perform cross-validation\n",
    "        cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "        return cv_scores_rf, measurement_rf, rf_model\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"⛔ Full error traceback:\")\n",
    "        traceback.print_exc()  # Print detailed error traceback\n",
    "        print(f\"Error during Random Forest training: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a64cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_RF(X_train, X_test, y_train, y_test):\n",
    "    params_rf = {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 8}\n",
    "\n",
    "    # Fitting the model\n",
    "    cv_scores_rf, measurement_rf, rf_model = apply_rf(X_train, y_train, best_params=params_rf)\n",
    "\n",
    "    # Making predictions\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model performance on the cross validation set vs accuracy on the test set\n",
    "    cv_scores_mean_rf = np.mean(cv_scores_rf)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_rf:.4f} +/- standard deviation: {np.std(cv_scores_rf):.4f}')\n",
    "\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    print(f'Accuracy on the test set: {accuracy_rf:.4f}')\n",
    "    \n",
    "    # Checking computational cost\n",
    "    print(\"Resource measurements:\", measurement_rf)\n",
    "    print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b82933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dataset_w_KNN(X_train, X_test, y_train, y_test):\n",
    "    params_knn = {'n_neighbors': 3, 'weights': 'uniform', 'algorithm': 'kd_tree', 'leaf_size': 100, 'p': 1}\n",
    "    \n",
    "    # Fitting the model\n",
    "    cv_scores_knn, measurement_knn, knn_model = apply_knn(X_train, y_train, best_params=params_knn)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_pred_knn = knn_model.predict(X_test)\n",
    "    \n",
    "    # Evaluating the model performance on the cross validation set vs accuracy on the test set\n",
    "    cv_scores_mean_knn = np.mean(cv_scores_knn)\n",
    "    print(f'Cross validation average score: {cv_scores_mean_knn:.4f} +/- standard deviation: {np.std(cv_scores_knn):.4f}')\n",
    "    \n",
    "    accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    print(f'Accuracy on the test set: {accuracy_knn:.4f}')\n",
    "    \n",
    "    # Checking computational cost\n",
    "    print(\"Resource measurements:\", measurement_knn)\n",
    "    print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb508bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_knn(X_train, y_train, best_params=None, random_state=42, n_jobs=-1, cv=5):\n",
    "    measurement_knn = {}\n",
    "    \n",
    "    # Default to empty dictionary if best_params is not provided\n",
    "    best_params = best_params or {}\n",
    "    \n",
    "    knn_model = KNeighborsClassifier(**best_params, n_jobs=n_jobs)\n",
    "    \n",
    "    # Function to monitor CPU usage during training\n",
    "    cpu_usage = []\n",
    "    stop_flag = threading.Event()\n",
    "    \n",
    "    def monitor_cpu():\n",
    "        while not stop_flag.is_set():\n",
    "            cpu_usage.append(psutil.cpu_percent(interval=0.1))\n",
    "    \n",
    "    # Function to train the model\n",
    "    def train_model():\n",
    "        knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    try:\n",
    "        # Start CPU monitoring in a separate thread\n",
    "        cpu_thread = threading.Thread(target=monitor_cpu)\n",
    "        cpu_thread.start()\n",
    "        \n",
    "        # Measure memory usage and training time\n",
    "        start_time = time.time()\n",
    "        train_model()\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Stop CPU monitoring\n",
    "        stop_flag.set()\n",
    "        cpu_thread.join()\n",
    "        \n",
    "        # Add measurements\n",
    "        measurement_knn['Training Time (s)'] = training_time\n",
    "        measurement_knn['Peak CPU Usage (%)'] = max(cpu_usage)\n",
    "        measurement_knn['Average CPU Usage (%)'] = sum(cpu_usage) / len(cpu_usage) if cpu_usage else 0\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores_knn = cross_val_score(knn_model, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "        \n",
    "        return cv_scores_knn, measurement_knn, knn_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(\"⛔ Full error traceback:\")\n",
    "        traceback.print_exc()  # Print detailed error traceback\n",
    "        print(f\"Error during KNN training: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317cccbe",
   "metadata": {},
   "source": [
    "# Data balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4b31da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "df = pd.read_csv(\"..\\..\\data prep\\cicids2018_prep\\cicids2018_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101d2cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal Traffic', 'Bot', 'DoS', 'Brute Force', 'DDoS',\n",
       "       'Infilteration'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Attack Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe1ee2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51df8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training and test splits\n",
    "X = df.drop('Attack Type', axis=1)\n",
    "y = df['Attack Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776d7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize scaling algos\n",
    "RS = RobustScaler()\n",
    "X_train_RS_scaled = RS.fit_transform(X_train)\n",
    "X_test_RS_scaled = RS.transform(X_test)\n",
    "\n",
    "SS = StandardScaler()\n",
    "X_train_SS_scaled = SS.fit_transform(X_train)\n",
    "X_test_SS_scaled = SS.transform(X_test)\n",
    "\n",
    "MMS = MinMaxScaler()\n",
    "X_train_MMS_scaled = MMS.fit_transform(X_train)\n",
    "X_test_MMS_scaled = MMS.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f7e2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Type\n",
      "Normal Traffic    8634196\n",
      "DDoS               775470\n",
      "DoS                196299\n",
      "Bot                143977\n",
      "Infilteration      107531\n",
      "Brute Force         94876\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Attack Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24942e7",
   "metadata": {},
   "source": [
    "## Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b228c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  6.8min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 150 out of 150 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9817 +/- standard deviation: 0.0011\n",
      "Accuracy on the test set: 0.9816\n",
      "Resource measurements: {'Training Time (s)': 415.8986060619354, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 93.0798055678303}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bot       1.00      0.99      0.99     43193\n",
      "   Brute Force       1.00      0.99      1.00     28463\n",
      "          DDoS       0.99      0.92      0.95    232641\n",
      "           DoS       0.99      0.98      0.98     58890\n",
      " Infilteration       0.00      0.00      0.00     32259\n",
      "Normal Traffic       0.98      1.00      0.99   2590259\n",
      "\n",
      "      accuracy                           0.98   2985705\n",
      "     macro avg       0.83      0.81      0.82   2985705\n",
      "  weighted avg       0.97      0.98      0.98   2985705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9685825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  6.2min finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 150 out of 150 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation average score: 0.9817 +/- standard deviation: 0.0002\n",
      "Accuracy on the test set: 0.9833\n",
      "Resource measurements: {'Training Time (s)': 381.7312135696411, 'Peak CPU Usage (%)': 100.0, 'Average CPU Usage (%)': 93.26440922190194}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "           Bot       1.00      0.99      0.99     43193\n",
      "   Brute Force       1.00      0.99      1.00     28463\n",
      "          DDoS       0.98      0.96      0.97    232641\n",
      "           DoS       0.99      0.98      0.99     58890\n",
      " Infilteration       0.00      0.00      0.00     32259\n",
      "Normal Traffic       0.98      1.00      0.99   2590259\n",
      "\n",
      "      accuracy                           0.98   2985705\n",
      "     macro avg       0.83      0.82      0.82   2985705\n",
      "  weighted avg       0.97      0.98      0.98   2985705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_RS_scaled, X_test_RS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbedd539",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43meval_dataset_w_RF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_SS_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_SS_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36meval_dataset_w_RF\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test)\u001b[39m\n\u001b[32m      2\u001b[39m params_rf = {\u001b[33m'\u001b[39m\u001b[33mn_estimators\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m150\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmin_samples_split\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmin_samples_leaf\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m8\u001b[39m}\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Fitting the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m cv_scores_rf, measurement_rf, rf_model = \u001b[43mapply_rf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_rf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Making predictions\u001b[39;00m\n\u001b[32m      8\u001b[39m y_pred_rf = rf_model.predict(X_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mapply_rf\u001b[39m\u001b[34m(X_train, y_train, best_params, random_state, n_jobs, cv)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Measure memory usage and training time\u001b[39;00m\n\u001b[32m     27\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m training_time = time.time() - start_time\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Stop CPU monitoring\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mapply_rf.<locals>.train_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mrf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1145\u001b[39m     estimator._validate_params()\n\u001b[32m   1147\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1148\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1149\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1150\u001b[39m     )\n\u001b[32m   1151\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:390\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    383\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    384\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSum of y is not strictly positive which \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis necessary for Poisson regression.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    386\u001b[39m         )\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m.n_outputs_ = y.shape[\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m y, expanded_class_weight = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) != DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y.flags.contiguous:\n\u001b[32m    393\u001b[39m     y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:749\u001b[39m, in \u001b[36mForestClassifier._validate_y_class_weight\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     y = np.copy(y)\n\u001b[32m    752\u001b[39m     expanded_class_weight = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:208\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_classification_targets\u001b[39m(y):\n\u001b[32m    197\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[32m    198\u001b[39m \n\u001b[32m    199\u001b[39m \u001b[33;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m \u001b[33;03m        Target values.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     y_type = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m     ]:\n\u001b[32m    216\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    217\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    220\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:388\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n\u001b[32m    387\u001b[39m first_row = y[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y.getrow(\u001b[32m0\u001b[39m).data\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.shape[\u001b[32m0\u001b[39m] > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row) > \u001b[32m1\u001b[39m):\n\u001b[32m    389\u001b[39m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m + suffix\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:262\u001b[39m, in \u001b[36m_NumPyAPIWrapper.unique_values\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<__array_function__ internals>:180\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    272\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\!STUDY\\1TMO\\4 Сем\\ДИПЛОМ\\CODE\\NN-env\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:338\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[39m\n\u001b[32m    336\u001b[39m     ar.sort()\n\u001b[32m    337\u001b[39m     aux = ar\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m mask = np.empty(aux.shape, dtype=np.bool_)\n\u001b[32m    339\u001b[39m mask[:\u001b[32m1\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (equal_nan \u001b[38;5;129;01mand\u001b[39;00m aux.shape[\u001b[32m0\u001b[39m] > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m aux.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcfmM\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    341\u001b[39m         np.isnan(aux[-\u001b[32m1\u001b[39m])):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "eval_dataset_w_RF(X_train_SS_scaled, X_test_SS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95270f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_MMS_scaled, X_test_MMS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84792a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fdd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_RS_scaled, X_test_RS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_SS_scaled, X_test_SS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df26d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_MMS_scaled, X_test_MMS_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f74929",
   "metadata": {},
   "source": [
    "## Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68795543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the undersampling for the clean df\n",
    "X_train_resampled_rus, y_train_resampled_rus = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "# Initializing the undersampling for the scaled df\n",
    "X_train_scaled_rus_RS, y_train_scaled_rus_RS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train_RS_scaled, y_train)\n",
    "\n",
    "X_train_scaled_rus_SS, y_train_scaled_rus_SS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train_SS_scaled, y_train)\n",
    "\n",
    "X_train_scaled_rus_MMS, y_train_scaled_rus_MMS = RandomUnderSampler(sampling_strategy={'Normal Traffic': 1000000}, random_state=42).fit_resample(X_train_MMS_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9dc7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the undersampling for the clean df\n",
    "X_train_resampled_NM, y_train_resampled_NM = NearMiss(sampling_strategy={'Normal Traffic': 1000000}, version=3).fit_resample(X_train, y_train)\n",
    "\n",
    "# Initializing the undersampling for the scaled df\n",
    "X_train_scaled_NM_RS, y_train_scaled_NM_RS = NearMiss(sampling_strategy={'Normal Traffic': 1000000}, version=3).fit_resample(X_train_RS_scaled, y_train)\n",
    "\n",
    "X_train_scaled_NM_SS, y_train_scaled_NM_SS = NearMiss(sampling_strategy={'Normal Traffic': 1000000}, version=3).fit_resample(X_train_SS_scaled, y_train)\n",
    "\n",
    "X_train_scaled_NM_MMS, y_train_scaled_NM_MMS = NearMiss(sampling_strategy={'Normal Traffic': 1000000}, version=3).fit_resample(X_train_MMS_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe75c8",
   "metadata": {},
   "source": [
    "## Evals RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_rus, X_test, y_train_resampled_rus, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60515714",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_rus_RS, X_test_RS_scaled, y_train_scaled_rus_RS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_rus_SS, X_test_SS_scaled, y_train_scaled_rus_SS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a814c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_rus_MMS, X_test_MMS_scaled, y_train_scaled_rus_MMS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62caeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_NM, X_test, y_train_resampled_NM, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_NM_RS, X_test_RS_scaled, y_train_scaled_NM_RS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf922f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_NM_SS, X_test_SS_scaled, y_train_scaled_NM_SS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_scaled_NM_MMS, X_test_MMS_scaled, y_train_scaled_NM_MMS, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3fa33",
   "metadata": {},
   "source": [
    "## Evals KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bfd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_rus, X_test, y_train_resampled_rus, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27743a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_rus_RS, X_test_RS_scaled, y_train_scaled_rus_RS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_rus_SS, X_test_SS_scaled, y_train_scaled_rus_SS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_rus_MMS, X_test_MMS_scaled, y_train_scaled_rus_MMS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_NM, X_test, y_train_resampled_NM, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c3b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_NM_RS, X_test_RS_scaled, y_train_scaled_NM_RS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_NM_SS, X_test_SS_scaled, y_train_scaled_NM_SS, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_scaled_NM_MMS, X_test_MMS_scaled, y_train_scaled_NM_MMS, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4bff5",
   "metadata": {},
   "source": [
    "## Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71464ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbb1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled_ADASYN, y_train_resampled_ADASYN = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5).fit_resample(X_train_resampled_rus, y_train_resampled_rus)\n",
    "\n",
    "X_train_resampled_scaled_RS_ADASYN, y_train_resampled_scaled_RS_ADASYN = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5).fit_resample(X_train_scaled_rus_RS, y_train_scaled_rus_RS)\n",
    "\n",
    "X_train_resampled_scaled_MMS_ADASYN, y_train_resampled_scaled_MMS_ADASYN = ADASYN(sampling_strategy='auto', random_state=42, n_neighbors=5).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)\n",
    "\n",
    "\n",
    "X_train_resampled_SMOTE, y_train_resampled_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_resampled_rus, y_train_resampled_rus)\n",
    "\n",
    "X_train_resampled_scaled_RS_SMOTE, y_train_resampled_scaled_RS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_RS, y_train_scaled_rus_RS)\n",
    "\n",
    "X_train_resampled_scaled_MMS_SMOTE, y_train_resampled_scaled_MMS_SMOTE = SMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS':780000, 'DoS': 200000}, random_state=42).fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)\n",
    "\n",
    "\n",
    "X_train_resampled_BSMOTE, y_train_resampled_BSMOTE = BorderlineSMOTE(sampling_strategy={'Bots': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS': 780000, 'DoS': 200000}, random_state=42, k_neighbors=5, m_neighbors=10, kind='borderline-1').fit_resample(X_train_resampled_rus, y_train_resampled_rus)\n",
    "\n",
    "X_train_resampled_scaled_RS_BSMOTE, y_train_resampled_scaled_RS_BSMOTE = BorderlineSMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS': 780000, 'DoS': 200000}, random_state=42, k_neighbors=5, m_neighbors=10, kind='borderline-1').fit_resample(X_train_scaled_rus_RS, y_train_scaled_rus_RS)\n",
    "\n",
    "X_train_resampled_scaled_MMS_BSMOTE, y_train_resampled_scaled_MMS_BSMOTE = BorderlineSMOTE(sampling_strategy={'Bot': 150000, 'Brute Force': 100000, 'Infilteration': 110000, 'DDoS': 780000, 'DoS': 200000}, random_state=42, k_neighbors=5, m_neighbors=10, kind='borderline-1').fit_resample(X_train_scaled_rus_MMS, y_train_scaled_rus_MMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf02a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_rus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f7f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_ADASYN.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_SMOTE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6eb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resampled_scaled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73abf9",
   "metadata": {},
   "source": [
    "## Eval RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_ADASYN, X_test, y_train_resampled_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075eb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_RS_ADASYN, X_test_RS_scaled, y_train_resampled_scaled_RS_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4dcfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_ADASYN, X_test_MMS_scaled, y_train_resampled_scaled_MMS_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f7c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_SMOTE, X_test, y_train_resampled_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_RS_SMOTE, X_test_RS_scaled, y_train_resampled_scaled_RS_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cbd5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_BSMOTE, X_test, y_train_resampled_BSMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b85c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_RS_BSMOTE, X_test_RS_scaled, y_train_resampled_scaled_RS_BSMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91c4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_RF(X_train_resampled_scaled_MMS_BSMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_BSMOTE, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb67bbb",
   "metadata": {},
   "source": [
    "## Eval KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_ADASYN, X_test, y_train_resampled_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_RS_ADASYN, X_test_RS_scaled, y_train_resampled_scaled_RS_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313e70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_MMS_ADASYN, X_test_MMS_scaled, y_train_resampled_scaled_MMS_ADASYN, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cca66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_SMOTE, X_test, y_train_resampled_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0964b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_RS_SMOTE, X_test_RS_scaled, y_train_resampled_scaled_RS_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_MMS_SMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_SMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ceacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_BSMOTE, X_test, y_train_resampled_BSMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eeb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_RS_BSMOTE, X_test_RS_scaled, y_train_resampled_scaled_RS_BSMOTE, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee05e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_w_KNN(X_train_resampled_scaled_MMS_BSMOTE, X_test_MMS_scaled, y_train_resampled_scaled_MMS_BSMOTE, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
